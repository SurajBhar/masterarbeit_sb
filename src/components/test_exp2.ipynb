{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU device: Tesla V100-SXM2-32GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print('GPU device:',torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print('No GPU avaialable, Using CPU')\n",
    "\n",
    "torch.cuda.set_device(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sur06423/miniconda3/envs/vi_trans/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Standard Library Imports\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import logging\n",
    "import getpass\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "import random\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "\n",
    "# Third-Party Library Imports\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local Imports\n",
    "sys.path.append('/home/sur06423/hiwi/vit_exp/vision_tranformer_baseline')\n",
    "from src.components import data_setup\n",
    "from src.components.dataset import ImageFolderCustom\n",
    "from src.components import utils\n",
    "from src.components.config_manager_baseline import get_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_time(seconds):\n",
    "    \"\"\"Converts time in seconds to hours, minutes, and seconds format.\"\"\"\n",
    "    hours = seconds // 3600\n",
    "    minutes = (seconds % 3600) // 60\n",
    "    seconds = seconds % 60\n",
    "    return f\"{int(hours)} hours, {int(minutes)} minutes, {int(seconds)} seconds\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_balanced_accuracy(y_pred, y_true, num_classes, epsilon=1e-9):\n",
    "    \"\"\"\n",
    "    Calculates the balanced accuracy score.\n",
    "    \n",
    "    Args:\n",
    "        y_pred (torch.Tensor): Predicted labels.\n",
    "        y_true (torch.Tensor): True labels.\n",
    "        num_classes (int): Number of classes in the dataset.\n",
    "        epsilon (float): A small value to add to denominators to prevent division by zero.\n",
    "        \n",
    "    Returns:\n",
    "        float: Balanced accuracy score.\n",
    "    \"\"\"\n",
    "    # Create confusion matrix\n",
    "    confusion_matrix = torch.zeros(num_classes, num_classes, device=y_pred.device)\n",
    "    for t, p in zip(y_true.view(-1), y_pred.view(-1)):\n",
    "        confusion_matrix[t.long(), p.long()] += 1\n",
    "\n",
    "    # Calculate recall for each class, adding epsilon to avoid division by zero\n",
    "    # Recall =  dividing the true positives by the sum of the true positive and false negative for each class\n",
    "    # Recall = (diagonal elements of the confusion matrix) /  (the sum of elements in each row of the confusion matrix + epsilon)\n",
    "    recall = torch.diag(confusion_matrix) / (confusion_matrix.sum(1) + epsilon)\n",
    "\n",
    "    # balanced_accuracy_per_class = recall  # This line is technically not needed but added for clarity\n",
    "\n",
    "    # Calculate balanced accuracy\n",
    "    balanced_accuracy = recall.mean().item()\n",
    "\n",
    "    return balanced_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_train_objs(model, num_epochs, optimizer_choice, scheduler_choice, initial_lr, momentum, weight_decay_adam, wd_sgd):\n",
    "    # Setup the optimizer\n",
    "    if optimizer_choice == 'ADAM':\n",
    "        optimizer = optim.Adam(\n",
    "            params=model.parameters(),\n",
    "            lr=initial_lr,\n",
    "            betas=(0.9, 0.999),\n",
    "            weight_decay=weight_decay_adam\n",
    "        )\n",
    "    elif optimizer_choice == 'SGD':\n",
    "        optimizer = optim.SGD(\n",
    "            params=model.parameters(),\n",
    "            lr=initial_lr,\n",
    "            momentum=momentum,\n",
    "            weight_decay=wd_sgd\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(\"Invalid optimizer choice. Choose 'adam' or 'sgd'.\")\n",
    "\n",
    "    # Define the lambda function for learning rate scheduling\n",
    "    def lr_lambda(epoch):\n",
    "        # Decrease the learning rate by a factor of 10 every 30 epochs\n",
    "        return 0.1 ** (epoch // 30)\n",
    "\n",
    "    # Setup the learning rate scheduler\n",
    "    if scheduler_choice == 'CosineAnnealingLR':\n",
    "        lr_scheduler = optim.lr_scheduler.CosineAnnealingLR(\n",
    "            optimizer,\n",
    "            T_max=num_epochs\n",
    "        )\n",
    "    elif scheduler_choice == 'LambdaLR':\n",
    "        lr_scheduler = optim.lr_scheduler.LambdaLR(\n",
    "            optimizer,\n",
    "            lr_lambda=lr_lambda  # Used the custom lambda function\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(\"Invalid scheduler choice. Choose 'LambdaLR' or 'CosineAnnealingLR'\")\n",
    "    \n",
    "    return optimizer, lr_scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets\n",
    "\n",
    "def prepare_dataset():\n",
    "    pretrained_vit_weights = torchvision.models.ViT_B_16_Weights.DEFAULT\n",
    "    pretrained_vit = torchvision.models.vit_b_16(weights=pretrained_vit_weights)\n",
    "\n",
    "    # Freeze the base parameters\n",
    "    for parameter in pretrained_vit.parameters():\n",
    "        parameter.requires_grad = False\n",
    "\n",
    "    # Change the classifier head\n",
    "    pretrained_vit.heads = nn.Linear(in_features=768, out_features=3)\n",
    "    pretrained_vit_transforms = pretrained_vit_weights.transforms()\n",
    "    # Convert the string path to a Path object\n",
    "    image_path = Path(\"/home/sur06423/hiwi/vit_exp/vision_tranformer_baseline/src/ddp_code/data_pizza/pizza_steak_sushi\")\n",
    "    train_dir = image_path / \"train\"\n",
    "    test_dir = image_path / \"test\"\n",
    "    \n",
    "    # Use ImageFolder to create dataset(s)\n",
    "    train_dataset = datasets.ImageFolder(str(train_dir), transform=pretrained_vit_transforms)\n",
    "    val_dataset = datasets.ImageFolder(str(test_dir), transform=pretrained_vit_transforms)\n",
    "\n",
    "    # Get class names\n",
    "    class_names = train_dataset.classes\n",
    "\n",
    "    return train_dataset, val_dataset, class_names, pretrained_vit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataloader(dataset: Dataset, batch_size: int, num_workers, prefetch_factor):\n",
    "    return DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True,\n",
    "        shuffle=False,\n",
    "        drop_last = False,\n",
    "        prefetch_factor = prefetch_factor\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here you can change things for experimentation\n",
    "batch_size = 64\n",
    "prefetch_factor = 2\n",
    "num_epochs = 10\n",
    "\n",
    "optimizer = 'SGD'\n",
    "scheduler = 'CosineAnnealingLR'\n",
    "lr = 0.001\n",
    "momentum = 0.9\n",
    "weight_decay = 0.0001\n",
    "w_decay_adam = 0.03\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    torch.cuda.set_device(0)\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print('No GPU avaialable, Using CPU')\n",
    "\n",
    "# device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "utils.set_seeds(1)\n",
    "num_workers = os.cpu_count()\n",
    "\n",
    "train_dataset, val_dataset, class_names, pretrained_vit = prepare_dataset()\n",
    "train_dataloader = prepare_dataloader(dataset= train_dataset, batch_size = batch_size, num_workers = num_workers, prefetch_factor = prefetch_factor)\n",
    "val_dataloader = prepare_dataloader(dataset= val_dataset, batch_size = batch_size, num_workers = num_workers, prefetch_factor = prefetch_factor)\n",
    "\n",
    "optimizer, lr_scheduler = load_train_objs(pretrained_vit, \n",
    "                                            num_epochs, \n",
    "                                            optimizer, \n",
    "                                            scheduler, \n",
    "                                            lr, \n",
    "                                            momentum, \n",
    "                                            w_decay_adam, \n",
    "                                            weight_decay\n",
    "                                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225\n",
      "4\n",
      "75\n",
      "2\n",
      "64\n"
     ]
    }
   ],
   "source": [
    "print(len(train_dataloader.dataset))\n",
    "print(len(train_dataloader))\n",
    "print(len(val_dataloader.dataset))\n",
    "print(len(val_dataloader))\n",
    "print(train_dataloader.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "def train_epoch(model, dataloader, optimizer, gpu_id, num_classes):\n",
    "    model.to(gpu_id)\n",
    "    model.train()\n",
    "    running_loss, correct_predictions, num_samples = 0, 0, 0\n",
    "    y_pred_all, y_all = [], []\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(gpu_id), y.to(gpu_id)\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(X)\n",
    "        loss = F.cross_entropy(y_pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * X.size(0)\n",
    "        y_pred_class = torch.argmax(torch.softmax(y_pred, dim=1), dim=1)\n",
    "        correct_predictions += (y_pred_class == y).type(torch.float).sum().item()\n",
    "        num_samples += X.size(0)\n",
    "        y_pred_all.append(y_pred_class)\n",
    "        y_all.append(y)\n",
    "    metrics = calculate_metrics(running_loss, correct_predictions, num_samples, y_pred_all, y_all, num_classes)\n",
    "    return metrics\n",
    "\n",
    "def validate_epoch(model, dataloader, gpu_id, num_classes):\n",
    "    model.to(gpu_id)\n",
    "    model.eval()\n",
    "    running_loss, correct_predictions, num_samples = 0, 0, 0\n",
    "    y_pred_all, y_all = [], []\n",
    "    with torch.no_grad():\n",
    "        for batch, (X, y) in enumerate(dataloader):\n",
    "            X, y = X.to(gpu_id), y.to(gpu_id)\n",
    "            y_pred = model(X)\n",
    "            loss = F.cross_entropy(y_pred, y)\n",
    "            running_loss += loss.item() * X.size(0)\n",
    "            y_pred_class = torch.argmax(torch.softmax(y_pred, dim=1), dim=1)\n",
    "            correct_predictions += (y_pred_class == y).type(torch.float).sum().item()\n",
    "            num_samples += X.size(0)\n",
    "            y_pred_all.append(y_pred_class)\n",
    "            y_all.append(y)\n",
    "    metrics = calculate_metrics(running_loss, correct_predictions, num_samples, y_pred_all, y_all, num_classes)\n",
    "    return metrics\n",
    "\n",
    "def calculate_metrics(running_loss, correct_predictions, num_samples, y_pred_all, y_all, num_classes):\n",
    "    avg_loss = running_loss / num_samples\n",
    "    avg_accuracy = correct_predictions / num_samples\n",
    "    balanced_accuracy = calculate_balanced_accuracy(torch.concatenate(y_pred_all), torch.concatenate(y_all), num_classes)\n",
    "    # Cleanup\n",
    "    del y_pred_all, y_all\n",
    "    return avg_loss, avg_accuracy, balanced_accuracy\n",
    "\n",
    "def format_time(seconds):\n",
    "    hours = seconds // 3600\n",
    "    minutes = (seconds % 3600) // 60\n",
    "    seconds = seconds % 60\n",
    "    return f\"{int(hours)}h:{int(minutes)}m:{int(seconds)}s\"\n",
    "\n",
    "def training(max_epochs, num_classes, lr_scheduler, gpu_id, model, train_dataloader, optimizer, val_dataloader):\n",
    "    total_start_time = time.time()\n",
    "    for epoch in tqdm(range(max_epochs)):\n",
    "        train_metrics = train_epoch(model, train_dataloader, optimizer, gpu_id, num_classes)\n",
    "        lr_scheduler.step()\n",
    "        val_metrics = validate_epoch(model, val_dataloader, gpu_id, num_classes)\n",
    "        # Logging the metrics\n",
    "        print(f\"Epoch: {epoch} | Training - Loss: {train_metrics[0]}, Accuracy: {train_metrics[1]}, Balanced Acc: {train_metrics[2]}\")\n",
    "        print(f\"Epoch: {epoch} | Validation - Loss: {val_metrics[0]}, Accuracy: {val_metrics[1]}, Balanced Acc: {val_metrics[2]}\")\n",
    "    total_end_time = time.time()\n",
    "    print(f\"Total training and validation time: {format_time(total_end_time - total_start_time)}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:05<00:49,  5.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | Training - Loss: 0.6472325812445746, Accuracy: 0.8711111111111111, Balanced Acc: 0.8707549571990967\n",
      "Epoch: 0 | Validation - Loss: 0.5093457555770874, Accuracy: 0.88, Balanced Acc: 0.8802716135978699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [00:10<00:43,  5.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | Training - Loss: 0.4953925808270772, Accuracy: 0.9111111111111111, Balanced Acc: 0.9111966490745544\n",
      "Epoch: 1 | Validation - Loss: 0.3991367868582408, Accuracy: 0.92, Balanced Acc: 0.912529706954956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [00:16<00:38,  5.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 | Training - Loss: 0.4106656911638048, Accuracy: 0.9155555555555556, Balanced Acc: 0.9167379140853882\n",
      "Epoch: 2 | Validation - Loss: 0.3420335308710734, Accuracy: 0.92, Balanced Acc: 0.912529706954956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [00:21<00:32,  5.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 | Training - Loss: 0.3613481405046251, Accuracy: 0.9288888888888889, Balanced Acc: 0.9299003481864929\n",
      "Epoch: 3 | Validation - Loss: 0.31162968158721926, Accuracy: 0.92, Balanced Acc: 0.912529706954956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [00:27<00:28,  5.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 | Training - Loss: 0.3313290837075975, Accuracy: 0.9333333333333333, Balanced Acc: 0.9343447685241699\n",
      "Epoch: 4 | Validation - Loss: 0.2955687038103739, Accuracy: 0.92, Balanced Acc: 0.912529706954956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [00:33<00:22,  5.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 | Training - Loss: 0.31377708461549547, Accuracy: 0.9377777777777778, Balanced Acc: 0.9387892484664917\n",
      "Epoch: 5 | Validation - Loss: 0.2877530578772227, Accuracy: 0.92, Balanced Acc: 0.912529706954956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [00:38<00:16,  5.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6 | Training - Loss: 0.30467132574982114, Accuracy: 0.9422222222222222, Balanced Acc: 0.9432336688041687\n",
      "Epoch: 6 | Validation - Loss: 0.2846335061391195, Accuracy: 0.92, Balanced Acc: 0.912529706954956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [00:44<00:10,  5.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7 | Training - Loss: 0.30096037520302665, Accuracy: 0.9422222222222222, Balanced Acc: 0.9432336688041687\n",
      "Epoch: 7 | Validation - Loss: 0.2839108137289683, Accuracy: 0.92, Balanced Acc: 0.912529706954956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [00:49<00:05,  5.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8 | Training - Loss: 0.3001131491528617, Accuracy: 0.9422222222222222, Balanced Acc: 0.9432336688041687\n",
      "Epoch: 8 | Validation - Loss: 0.2839108137289683, Accuracy: 0.92, Balanced Acc: 0.912529706954956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:54<00:00,  5.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9 | Training - Loss: 0.29988351517253453, Accuracy: 0.9422222222222222, Balanced Acc: 0.9432336688041687\n",
      "Epoch: 9 | Validation - Loss: 0.28326441287994386, Accuracy: 0.92, Balanced Acc: 0.912529706954956\n",
      "Total training and validation time: 0h:0m:54s.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "training(max_epochs = 10, \n",
    "         num_classes = 3, \n",
    "         lr_scheduler= lr_scheduler,  \n",
    "         gpu_id = device, \n",
    "         model= pretrained_vit, \n",
    "         train_dataloader= train_dataloader, \n",
    "         optimizer = optimizer, \n",
    "         val_dataloader = val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vi_trans",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
