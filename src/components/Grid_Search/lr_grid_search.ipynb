{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Feb 29 02:19:45 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.113.01             Driver Version: 535.113.01   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  Tesla V100-SXM2-32GB           Off | 00000000:06:00.0 Off |                    0 |\n",
      "| N/A   32C    P0              43W / 300W |      0MiB / 32768MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla V100-SXM2-32GB           Off | 00000000:07:00.0 Off |                    0 |\n",
      "| N/A   42C    P0             306W / 300W |   3319MiB / 32768MiB |     10%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   2  Tesla V100-SXM2-32GB           Off | 00000000:0A:00.0 Off |                    0 |\n",
      "| N/A   45C    P0              67W / 300W |    719MiB / 32768MiB |     16%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   3  Tesla V100-SXM2-32GB           Off | 00000000:0B:00.0 Off |                    0 |\n",
      "| N/A   56C    P0             302W / 300W |  18561MiB / 32768MiB |    100%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   4  Tesla V100-SXM2-32GB           Off | 00000000:85:00.0 Off |                    0 |\n",
      "| N/A   34C    P0              41W / 300W |      0MiB / 32768MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   5  Tesla V100-SXM2-32GB           Off | 00000000:86:00.0 Off |                    0 |\n",
      "| N/A   36C    P0              56W / 300W |   1097MiB / 32768MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   6  Tesla V100-SXM2-32GB           Off | 00000000:89:00.0 Off |                    0 |\n",
      "| N/A   60C    P0             110W / 300W |   5489MiB / 32768MiB |     80%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   7  Tesla V100-SXM2-32GB           Off | 00000000:8A:00.0 Off |                    0 |\n",
      "| N/A   54C    P0              92W / 300W |   4933MiB / 32768MiB |     87%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    1   N/A  N/A   1010935      C   python                                     3316MiB |\n",
      "|    2   N/A  N/A   3451093      C   python                                      716MiB |\n",
      "|    3   N/A  N/A     22675      C   ...anaconda3/envs/aic24/bin/python3.10    18552MiB |\n",
      "|    5   N/A  N/A    303021      C   python                                     1094MiB |\n",
      "|    6   N/A  N/A   1149246      C   python                                     5486MiB |\n",
      "|    7   N/A  N/A   1149246      C   python                                     4930MiB |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU device: Tesla V100-SXM2-32GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print('GPU device:',torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print('No GPU avaialable, Using CPU')\n",
    "\n",
    "torch.cuda.set_device(4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Maintaining Distribution with Stratified Sampling\n",
    "\n",
    "- To ensure that the distribution of the dataset splits is maintained in the subsets, especially when dealing with imbalanced datasets like DAA, we should ideally use stratified sampling. \n",
    "- Stratified sampling involves dividing the dataset into homogeneous subgroups before sampling, then drawing samples from these subgroups in such a way that the proportion of each subgroup in the sample matches the proportion in the full dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = \"/net/polaris/storage/deeplearning/sur_data/rgb_daa/split_0/train\"\n",
    "val_dir = \"/net/polaris/storage/deeplearning/sur_data/rgb_daa/split_0/val\"\n",
    "test_dir = \"/net/polaris/storage/deeplearning/sur_data/rgb_daa/split_0/test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import logging\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Local Imports\n",
    "sys.path.append('/home/sur06423/hiwi/vit_exp/vision_tranformer_baseline')\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from src.components import data_setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The parameters of the head layer in model requires gradient or are trainable ? Answer: True\n",
      " The parameters of the head layer in model requires gradient or are trainable ? Answer: True\n"
     ]
    }
   ],
   "source": [
    "pretrained_vit_weights = torchvision.models.ViT_B_16_Weights.DEFAULT\n",
    "pretrained_vit = torchvision.models.vit_b_16(weights=pretrained_vit_weights)\n",
    "\n",
    "# Freeze the base parameters\n",
    "for parameter in pretrained_vit.parameters():\n",
    "    parameter.requires_grad = False\n",
    "\n",
    "# Change the classifier head\n",
    "pretrained_vit.heads = nn.Linear(in_features=768, out_features=34)\n",
    "pretrained_vit_transforms = pretrained_vit_weights.transforms()\n",
    "\n",
    "# Make sure the head parameters are trainable: two print statements for two parameters : (Weight & Biases)\n",
    "for param in pretrained_vit.heads.parameters():\n",
    "    print(f\" The parameters of the head layer in model requires gradient or are trainable ? Answer: {param.requires_grad}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset for Grid Seach Experiment with slight modifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "import torch\n",
    "from typing import Tuple, Dict, List\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "\n",
    "class ImageFolderCustom(Dataset):\n",
    "    def __init__(self, targ_dir: str, transform=None, target_transform=None) -> None:\n",
    "        # Get all image paths\n",
    "        self.paths = list(pathlib.Path(targ_dir).glob(\"*/*/*.png\"))  # Adjust for different file types as needed\n",
    "        # Setup transforms\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        # Create classes and class_to_idx attributes\n",
    "        self.classes, self.class_to_idx = self.find_classes(targ_dir)\n",
    "        # Extract labels for all images\n",
    "        self.labels = [self.class_to_idx[path.parent.parent.name] for path in self.paths]\n",
    "\n",
    "    def load_image(self, index: int) -> Image.Image:\n",
    "        \"Opens an image via a path and returns it.\"\n",
    "        image_path = self.paths[index]\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        return image\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        \"Returns the total number of samples.\"\n",
    "        return len(self.paths)\n",
    "\n",
    "    def find_classes(self, directory: str) -> Tuple[List[str], Dict[str, int]]:\n",
    "        classes = sorted(entry.name for entry in os.scandir(directory) if entry.is_dir())\n",
    "        if not classes:\n",
    "            raise FileNotFoundError(f\"Couldn't find any classes in {directory}.\")\n",
    "        class_to_idx = {cls_name: i for i, cls_name in enumerate(classes)}\n",
    "        return classes, class_to_idx\n",
    "\n",
    "    def __getitem__(self, index: int) -> Tuple[torch.Tensor, int]:\n",
    "        \"Returns one sample of data, data and label (X, y).\"\n",
    "        image = self.load_image(index)\n",
    "        class_name = self.paths[index].parent.parent.name\n",
    "        class_idx = self.class_to_idx[class_name]\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform:\n",
    "            class_idx = self.target_transform(class_idx)\n",
    "\n",
    "        return image, class_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ImageFolderCustom(train_dir, transform=pretrained_vit_transforms)\n",
    "val_dataset = ImageFolderCustom(val_dir, transform=pretrained_vit_transforms)\n",
    "test_dataset = ImageFolderCustom(test_dir, transform=pretrained_vit_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of the train dataset is : 259865\n",
      "The length of the val dataset is : 56024\n",
      "The length of the test dataset is : 87315\n"
     ]
    }
   ],
   "source": [
    "print(f\"The length of the train dataset is : {train_dataset.__len__()}\")\n",
    "print(f\"The length of the val dataset is : {val_dataset.__len__()}\")\n",
    "print(f\"The length of the test dataset is : {test_dataset.__len__()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The label of the first sample in the train dataset is : 2\n"
     ]
    }
   ],
   "source": [
    "sample = train_dataset[0]\n",
    "print(f\" The label of the first sample in the train dataset is : {sample[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "259865"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset.labels)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DAA Dataset : rgb_daa/split_0\n",
    "- The length of the train dataset is : 259865\n",
    "- The length of the val dataset is : 56024\n",
    "- The length of the test dataset is : 87315"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Original Proportions: \n",
    "- 403204 Total Samples, 64.445% Train, 13.89% Val, 21.65% Test Set\n",
    "\n",
    "- Train : 20% 259865 = 51973\n",
    "- Val: 20% 56024 = 11204\n",
    "- Test: 20% 87315 = 17463\n",
    "- Total samples = 80640\n",
    "\n",
    "- New Proportions: 64.45% Train, 13.89% Val, 21.65% Test\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate Stratified Indices: \n",
    "\n",
    "- First, we need to use the train_test_split function from sklearn.model_selection to generate indices for stratified sampling. \n",
    "- This requires knowledge of the labels for each sample in your dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are taking 20% of the entire dataset for Grid search\n",
    "# This means we will take 20% samples by preserving their distribution from\n",
    "# each of the train, test and validation datasets.\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def get_stratified_indices(labels, test_size=0.2):\n",
    "    \"\"\"\n",
    "    The get_stratified_indices function:\n",
    "    It is a utility for generating a stratified subset of a dataset in PyTorch using indices, \n",
    "    leveraging sklearn's train_test_split for stratification. \n",
    "    This ensures that the class distribution in the subset matches that of the original dataset, \n",
    "    which is important for maintaining the integrity of machine learning models, \n",
    "    especially when dealing with imbalanced classes as in DAA.\n",
    "    \"\"\"\n",
    "    # Generate indices for a stratified split\n",
    "    # X_train, X_test, y_train, y_test\n",
    "    _, stratified_idx, _, _ = train_test_split(\n",
    "        range(len(labels)), labels, test_size=test_size, stratify=labels, random_state=42)\n",
    "    \n",
    "    return stratified_idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate stratified indices for each split\n",
    "train_indices = get_stratified_indices(train_dataset.labels)\n",
    "val_indices = get_stratified_indices(val_dataset.labels)\n",
    "test_indices = get_stratified_indices(test_dataset.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " the length of the stratified train indices is: 51973\n",
      " the length of the stratified val indices is: 11205\n",
      " the length of the stratified test indices is: 17463\n"
     ]
    }
   ],
   "source": [
    "print(f\" the length of the stratified train indices is: {len(train_indices)}\")\n",
    "print(f\" the length of the stratified val indices is: {len(val_indices)}\")\n",
    "print(f\" the length of the stratified test indices is: {len(test_indices)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- the length of the stratified train indices is: 51973\n",
    "- the length of the stratified val indices is: 11205\n",
    "- the length of the stratified test indices is: 17463"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def save_indices(train_indices, val_indices, test_indices, file_name='dataset_indices.json'):\n",
    "    \"\"\"\n",
    "    This function takes the train_indices, val_indices, and test_indices along with an optional \n",
    "    file_name parameter specifying the name of the file to save the indices to. \n",
    "    It first converts the indices into lists (necessary if your indices are in a format \n",
    "    that is not directly serializable to JSON, such as NumPy arrays or PyTorch tensors) \n",
    "    and then writes them to a file in JSON format.\n",
    "\n",
    "    Args:\n",
    "    train_indices: A list of stratified train samples subset, \n",
    "    val_indices: A list of stratified val samples subset, \n",
    "    test_indices:A list of stratified test samples subset,\n",
    "    file_name: A file name to store the data.\n",
    "\n",
    "    \"\"\"\n",
    "    # Create a dictionary to hold the indices\n",
    "    indices_dict = {\n",
    "        'train_indices': train_indices,  # Convert to list if using numpy arrays or tensors .tolist()\n",
    "        'val_indices': val_indices,\n",
    "        'test_indices': test_indices,\n",
    "    }\n",
    "    \n",
    "    # Open a file in write mode and save the JSON\n",
    "    with open(file_name, 'w') as file:\n",
    "        json.dump(indices_dict, file)\n",
    "\n",
    "# train_indices, val_indices, test_indices are available\n",
    "save_indices(train_indices, val_indices, test_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_indices(file_name='dataset_indices.json'):\n",
    "    \"\"\"\n",
    "    This function reads the indices from a JSON file specified by file_name,\n",
    "    assuming the structure matches what was saved by save_indices. \n",
    "    It then returns the train_indices, val_indices, and test_indices \n",
    "    for use in our dataset handling or training script.\n",
    "    \"\"\"\n",
    "    # Open the file and load the JSON\n",
    "    with open(file_name, 'r') as file:\n",
    "        indices_dict = json.load(file)\n",
    "    \n",
    "    # Convert lists back to the desired format, e.g., lists, numpy arrays, or tensors\n",
    "    train_indices = indices_dict['train_indices']\n",
    "    val_indices = indices_dict['val_indices']\n",
    "    test_indices = indices_dict['test_indices']\n",
    "    \n",
    "    return train_indices, val_indices, test_indices\n",
    "\n",
    "train_indices, val_indices, test_indices = load_indices()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply Stratified Indices to PyTorch Datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Subset\n",
    "\n",
    "# Creating subsets\n",
    "train_subset = Subset(train_dataset, train_indices)\n",
    "val_subset = Subset(val_dataset, val_indices)\n",
    "test_subset = Subset(test_dataset, test_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " the length of the stratified train subset is: 51973\n",
      " the length of the stratified val subset is: 11205\n",
      " the length of the stratified test subset is: 17463\n"
     ]
    }
   ],
   "source": [
    "print(f\" the length of the stratified train subset is: {len(train_subset)}\")\n",
    "print(f\" the length of the stratified val subset is: {len(val_subset)}\")\n",
    "print(f\" the length of the stratified test subset is: {len(test_subset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_subset[0][1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn images into data loaders\n",
    "train_dataloader = DataLoader(train_subset,batch_size=1024,shuffle=True,drop_last = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn images into data loaders\n",
    "val_dataloader = DataLoader(val_subset,batch_size=1024,shuffle=False,drop_last = False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trainer Class for experimentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Dataset: ImageNet | Steps: 20,000 | BaseLR {0.003, 0.01, 0.03, 0.06}\n",
    "\n",
    "Hyperparameters for fine-tuning (DAA Dataset):\n",
    "    SGD with a momentum of 0.9, \n",
    "    cosine learning rate decay,\n",
    "    a batch size of 1024, \n",
    "    no weight decay, \n",
    "    and grad clipping at global norm 1.\n",
    "    fine-tuning resolution is 224.\n",
    "    Epochs>79: 90 | Steps: 22,860\n",
    "    No Grid Search for Best LR.\n",
    "    Base LR: 0.003\n",
    "\"\"\"\n",
    "\n",
    "class Trainer:\n",
    "    def __init__(self,\n",
    "                 model: torch.nn.Module, \n",
    "                 train_dataloader, \n",
    "                 val_dataloader, \n",
    "                 optimizer_choice, \n",
    "                 scheduler_choice, \n",
    "                 lr, \n",
    "                 momentum, \n",
    "                 weight_decay, \n",
    "                 gpu_id, \n",
    "                 num_classes,\n",
    "                 num_epochs, \n",
    "                 log_dir, \n",
    "                 exp_name, \n",
    "                 save_every\n",
    "                 ):\n",
    "        self.gpu_id = gpu_id\n",
    "        self.model = model.to(gpu_id)\n",
    "        self.num_classes = num_classes\n",
    "        self.num_epochs = num_epochs\n",
    "        self.train_dataloader = train_dataloader\n",
    "        self.val_dataloader = val_dataloader\n",
    "        self.log_dir = log_dir\n",
    "        self.experiment_name = exp_name\n",
    "        self.save_every = save_every\n",
    "        self.writer = SummaryWriter(log_dir=self.log_dir)\n",
    "        self.logger = self.configure_logger()\n",
    "        self.optimizer = self.configure_optimizer(optimizer_choice, lr, momentum, weight_decay)\n",
    "        self.lr_scheduler = self.configure_scheduler(scheduler_choice, lr)\n",
    "\n",
    "    def configure_logger(self):\n",
    "        logger = logging.getLogger(__name__)\n",
    "        logger.setLevel(logging.INFO)\n",
    "        log_format = logging.Formatter(\"%(asctime)s - %(levelname)s - %(message)s\")\n",
    "        log_file_path = os.path.join(self.log_dir, \"training_log.log\")\n",
    "        file_handler = logging.FileHandler(log_file_path)\n",
    "        file_handler.setFormatter(log_format)\n",
    "        logger.addHandler(file_handler)\n",
    "        console_handler = logging.StreamHandler(sys.stdout)\n",
    "        console_handler.setFormatter(log_format)\n",
    "        logger.addHandler(console_handler)\n",
    "        return logger\n",
    "\n",
    "    def calculate_balanced_accuracy(self, y_pred, y_true, num_classes):\n",
    "        \"\"\"\n",
    "        Calculates the balanced accuracy score using PyTorch operations.\n",
    "        (y_pred == c): Creates a boolean tensor where each element is True \n",
    "        if the predicted label equals class c, and False otherwise.\n",
    "\n",
    "        (y_true == c): Creates another boolean tensor where each element is True \n",
    "        if the true label equals class c, and False otherwise.\n",
    "\n",
    "        &: Performs a logical AND operation between the two boolean tensors. \n",
    "        The result is a tensor where each element is True only if both conditions \n",
    "        are met: the predicted label is class c, and the true label is also class c. \n",
    "        This effectively filters out the true positives for class c.\n",
    "\n",
    "        .sum(): Sums up the True values in the resultant tensor, which corresponds\n",
    "        to the count of true positive predictions for class c.\n",
    "\n",
    "        Args:\n",
    "            y_pred (torch.Tensor): Tensor of predicted class labels( No Logits & Probabilities, only labels).\n",
    "            y_true (torch.Tensor): Tensor of true class labels.\n",
    "            num_classes (int): Number of classes.\n",
    "\n",
    "        Returns:\n",
    "            float: The balanced accuracy score.\n",
    "        \"\"\"\n",
    "        correct_per_class = torch.zeros(num_classes, device=y_pred.device)\n",
    "        total_per_class = torch.zeros(num_classes, device=y_pred.device)\n",
    "\n",
    "        for c in range(num_classes):\n",
    "            # The number of true positive predictions for class c. \n",
    "            # True positives are instances that are correctly identified as \n",
    "            # belonging to class c by the classifier.\n",
    "            true_positives = ((y_pred == c) & (y_true == c)).sum()\n",
    "            # Condition Positive: total number of instances that actually belong to class c, \n",
    "            # regardless of whether they were correctly identified by the classifier or not.\n",
    "            condition_positives = (y_true == c).sum()\n",
    "            \n",
    "            correct_per_class[c] = true_positives.float()\n",
    "            total_per_class[c] = condition_positives.float()\n",
    "\n",
    "        # .clamp(min=1) function ensures that no value in the total_per_class tensor is less than 1\n",
    "        recall_per_class = correct_per_class / total_per_class.clamp(min=1)\n",
    "        balanced_accuracy = recall_per_class.mean().item()  # Convert to Python scalar for compatibility\n",
    "\n",
    "        return balanced_accuracy\n",
    "\n",
    "    def configure_optimizer(self, optimizer_choice, initial_lr, momentum, weight_decay):\n",
    "        if optimizer_choice.lower() == 'adam':\n",
    "            optimizer = optim.Adam(self.model.parameters(), lr=initial_lr, weight_decay=weight_decay)\n",
    "        elif optimizer_choice.lower() == 'sgd':\n",
    "            optimizer = optim.SGD(self.model.parameters(), lr=initial_lr, momentum=momentum, weight_decay=weight_decay)\n",
    "        else:\n",
    "            raise ValueError(\"Invalid optimizer choice. Choose 'adam' or 'sgd'.\")\n",
    "        return optimizer\n",
    "\n",
    "    def configure_scheduler(self, scheduler_choice, initial_lr):\n",
    "        if scheduler_choice.lower() == 'cosineannealinglr':\n",
    "            lr_scheduler = optim.lr_scheduler.CosineAnnealingLR(self.optimizer, T_max=self.num_epochs)  # T_max=80, adjusted to \"num_epochs\"\n",
    "        elif scheduler_choice.lower() == 'lambdalr':\n",
    "            lr_lambda = lambda epoch: 0.1 ** (epoch // 30)\n",
    "            lr_scheduler = optim.lr_scheduler.LambdaLR(self.optimizer, lr_lambda=lr_lambda)\n",
    "        else:\n",
    "            raise ValueError(\"Invalid scheduler choice. Choose 'cosineannealinglr' or 'lambdalr'.\")\n",
    "        return lr_scheduler\n",
    "\n",
    "    def _train_epoch(self):\n",
    "        self.model.train()\n",
    "        running_loss,  num_samples = 0, 0\n",
    "        y_pred_all, y_all = [], []\n",
    "        for batch, (X, y) in enumerate(self.train_dataloader):\n",
    "            X, y = X.to(self.gpu_id), y.to(self.gpu_id)\n",
    "            self.optimizer.zero_grad()\n",
    "            y_pred = self.model(X)\n",
    "            loss = F.cross_entropy(y_pred, y)\n",
    "            loss.backward()\n",
    "\n",
    "            # Applying gradient clipping\n",
    "            torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1)\n",
    "\n",
    "            self.optimizer.step()\n",
    "            running_loss += loss.item() * X.size(0)\n",
    "            y_pred_class = torch.argmax(torch.softmax(y_pred, dim=1), dim=1)\n",
    "            \n",
    "            num_samples += X.size(0)\n",
    "            y_pred_all.append(y_pred_class)\n",
    "            y_all.append(y)\n",
    "        metrics = self._calculate_metrics(running_loss, num_samples, y_pred_all, y_all)\n",
    "        return metrics\n",
    "\n",
    "    def _validation_epoch(self):\n",
    "        self.model.eval()\n",
    "        running_loss, num_samples = 0, 0\n",
    "        y_pred_all, y_all = [], []\n",
    "        with torch.no_grad():\n",
    "            for X, y in self.val_dataloader:\n",
    "                X, y = X.to(self.gpu_id), y.to(self.gpu_id)\n",
    "                y_pred = self.model(X)\n",
    "                loss = F.cross_entropy(y_pred, y)\n",
    "                running_loss += loss.item() * X.size(0)\n",
    "                y_pred_class = torch.argmax(torch.softmax(y_pred, dim=1), dim=1)\n",
    "                \n",
    "                num_samples += X.size(0)\n",
    "                y_pred_all.append(y_pred_class)\n",
    "                y_all.append(y)\n",
    "        metrics = self._calculate_metrics(running_loss, num_samples, y_pred_all, y_all)\n",
    "        return metrics\n",
    "\n",
    "    def _calculate_metrics(self, running_loss,  num_samples, y_pred_all, y_all):\n",
    "        avg_loss = running_loss / num_samples\n",
    "        balanced_accuracy = self.calculate_balanced_accuracy(torch.concatenate(y_pred_all), torch.concatenate(y_all), self.num_classes)\n",
    "        return avg_loss, balanced_accuracy\n",
    "\n",
    "    def training_validation(self, max_epochs, resume=False, checkpoint_path=None):\n",
    "        total_start_time = time.time()\n",
    "        start_epoch = 0\n",
    "        if resume:\n",
    "            start_epoch = self.load_checkpoint(checkpoint_path)\n",
    "            self._log(f\"Resuming training from epoch {start_epoch}\")\n",
    "\n",
    "        for epoch in tqdm(range(start_epoch, max_epochs)):\n",
    "            # server_file.setup_ccname()\n",
    "            epoch_start_time = time.time()\n",
    "            train_metrics = self._train_epoch()\n",
    "            total_epoch_duration = time.time() - epoch_start_time\n",
    "            self._log(f\"Total training time for epoch {epoch}: {self._format_time(total_epoch_duration)}.\")\n",
    "\n",
    "            val_epoch_start_time = time.time()\n",
    "            val_metrics = self._validation_epoch()\n",
    "            total_epoch_val_duration = time.time() - val_epoch_start_time\n",
    "            self._log(f\"Total validation time for epoch {epoch}: {self._format_time(total_epoch_val_duration)}.\")\n",
    "\n",
    "            # Log metrics to TensorBoard and console\n",
    "            self.writer.add_scalar(\"Train/Loss\", train_metrics[0], epoch)\n",
    "            self.writer.add_scalar(\"Train/Balanced_Accuracy\", train_metrics[1], epoch)\n",
    "            self.writer.add_scalar(\"Validation/Loss\", val_metrics[0], epoch)\n",
    "            self.writer.add_scalar(\"Validation/Balanced_Accuracy\", val_metrics[1], epoch)\n",
    "\n",
    "            self._log(f\"Epoch: {epoch} | Train Loss: {train_metrics[0]:.4f} | Train Balanced Acc: {train_metrics[1] * 100:.4f} % | Val Loss: {val_metrics[0]:.4f} | Val Balanced Acc: {val_metrics[1] * 100:.4f} % \")\n",
    "\n",
    "            self.lr_scheduler.step()\n",
    "\n",
    "            if (epoch + 1) % self.save_every == 0:\n",
    "                self._save_checkpoint(epoch, train_metrics, val_metrics)\n",
    "\n",
    "        total_duration = time.time() - total_start_time\n",
    "        self._log(f\"Total training and validation time: {self._format_time(total_duration)}.\")\n",
    "        self.writer.close()\n",
    "\n",
    "    def _save_checkpoint(self, epoch, train_metrics, val_metrics):\n",
    "        checkpoint_dir = os.path.join(self.log_dir, \"checkpoints\")\n",
    "        os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "        checkpoint_path = os.path.join(checkpoint_dir, f\"checkpoint_{self.experiment_name}_epoch_{epoch}.pth\")\n",
    "        \n",
    "        # Prepare the checkpoint dictionary\n",
    "        checkpoint_dict = {\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': self.model.state_dict(),\n",
    "            'optimizer_state_dict': self.optimizer.state_dict(),\n",
    "            'train_loss': train_metrics[0],\n",
    "            'val_loss': val_metrics[0],\n",
    "            'train_balanced_accuracy': train_metrics[1],\n",
    "            'val_balanced_accuracy': val_metrics[1],\n",
    "            # Saving the current learning rate (from the first param group)\n",
    "            'current_lr': self.optimizer.param_groups[0]['lr']\n",
    "        }\n",
    "        \n",
    "        # If a learning rate scheduler is used, save its state as well\n",
    "        if hasattr(self, 'lr_scheduler') and self.lr_scheduler is not None:\n",
    "            checkpoint_dict['scheduler_state_dict'] = self.lr_scheduler.state_dict()\n",
    "        \n",
    "        torch.save(checkpoint_dict, checkpoint_path)\n",
    "        self._log(f\"Saved checkpoint at epoch {epoch}: {checkpoint_path}\")\n",
    "\n",
    "    def _log(self, message):\n",
    "        # print(message) # Uncomment if you want to print it\n",
    "        self.logger.info(message)\n",
    "\n",
    "    def _format_time(self, seconds):\n",
    "        hours = seconds // 3600\n",
    "        minutes = (seconds % 3600) // 60\n",
    "        seconds = seconds % 60\n",
    "        return f\"{int(hours)}h:{int(minutes)}m:{int(seconds)}s\"\n",
    "    \n",
    "    def load_checkpoint(self, checkpoint_path):\n",
    "        checkpoint = torch.load(checkpoint_path)\n",
    "        self.model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        \n",
    "        # Load the current learning rate back into the optimizer, if it was saved\n",
    "        if 'current_lr' in checkpoint:\n",
    "            for param_group in self.optimizer.param_groups:\n",
    "                param_group['lr'] = checkpoint['current_lr']\n",
    "        \n",
    "        # If a learning rate scheduler state was saved, load it as well\n",
    "        if hasattr(self, 'lr_scheduler') and self.lr_scheduler is not None and 'scheduler_state_dict' in checkpoint:\n",
    "            self.lr_scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "\n",
    "        return checkpoint['epoch']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LR: {0.003, 0.01, 0.03, 0.06}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurations of the experiment 1\n",
    "experiment_name = \"Exp_001_LR_0.01\"\n",
    "num_epochs = 80\n",
    "num_classes = 34\n",
    "save_every = 20\n",
    "optimizer = 'SGD'\n",
    "scheduler = 'CosineAnnealingLR'\n",
    "lr = 0.01 # {0.003,0.01,0.03,0.06}\n",
    "momentum = 0.9\n",
    "weight_decay = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main function for Experiment\n",
    "def main(train_dataloader, val_dataloader):\n",
    "    log_dir = os.path.join(\"experiments\", experiment_name, \"runs\")\n",
    "    os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model = pretrained_vit,\n",
    "        train_dataloader=train_dataloader,\n",
    "        val_dataloader=val_dataloader,\n",
    "        optimizer_choice=optimizer,\n",
    "        scheduler_choice=scheduler,\n",
    "        lr=lr,\n",
    "        momentum=momentum,\n",
    "        weight_decay=weight_decay,\n",
    "        gpu_id=device,\n",
    "        num_classes=num_classes,\n",
    "        num_epochs=num_epochs,\n",
    "        log_dir=log_dir,\n",
    "        exp_name=experiment_name,\n",
    "        save_every=save_every\n",
    "    )\n",
    "\n",
    "    trainer.training_validation(max_epochs=num_epochs, resume=False, checkpoint_path=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/80 [00:00<?, ?it/s]/home/sur06423/miniconda3/envs/vi_trans/lib/python3.10/site-packages/torch/nn/modules/conv.py:456: UserWarning: Applied workaround for CuDNN issue, install nvrtc.so (Triggered internally at /opt/conda/conda-bld/pytorch_1704987280714/work/aten/src/ATen/native/cudnn/Conv_v8.cpp:80.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-29 03:12:02,817 - INFO - Total training time for epoch 0: 0h:21m:2s.\n",
      "2024-02-29 03:12:02,817 - INFO - Total training time for epoch 0: 0h:21m:2s.\n",
      "2024-02-29 03:29:49,794 - INFO - Total validation time for epoch 0: 0h:17m:46s.\n",
      "2024-02-29 03:29:49,794 - INFO - Total validation time for epoch 0: 0h:17m:46s.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/80 [38:49<?, ?it/s]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m main(train_dataloader, val_dataloader)\n",
      "Cell \u001b[0;32mIn[37], line 23\u001b[0m, in \u001b[0;36mmain\u001b[0;34m(train_dataloader, val_dataloader)\u001b[0m\n\u001b[1;32m      4\u001b[0m os\u001b[39m.\u001b[39mmakedirs(log_dir, exist_ok\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m      6\u001b[0m trainer \u001b[39m=\u001b[39m Trainer(\n\u001b[1;32m      7\u001b[0m     model \u001b[39m=\u001b[39m pretrained_vit,\n\u001b[1;32m      8\u001b[0m     train_dataloader\u001b[39m=\u001b[39mtrain_dataloader,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     20\u001b[0m     save_every\u001b[39m=\u001b[39msave_every\n\u001b[1;32m     21\u001b[0m )\n\u001b[0;32m---> 23\u001b[0m trainer\u001b[39m.\u001b[39;49mtraining_validation(max_epochs\u001b[39m=\u001b[39;49mnum_epochs, resume\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, checkpoint_path\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m)\n",
      "Cell \u001b[0;32mIn[34], line 197\u001b[0m, in \u001b[0;36mTrainer.training_validation\u001b[0;34m(self, max_epochs, resume, checkpoint_path)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwriter\u001b[39m.\u001b[39madd_scalar(\u001b[39m\"\u001b[39m\u001b[39mValidation/Loss\u001b[39m\u001b[39m\"\u001b[39m, val_metrics[\u001b[39m0\u001b[39m], epoch)\n\u001b[1;32m    195\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwriter\u001b[39m.\u001b[39madd_scalar(\u001b[39m\"\u001b[39m\u001b[39mValidation/Balanced_Accuracy\u001b[39m\u001b[39m\"\u001b[39m, val_metrics[\u001b[39m1\u001b[39m], epoch)\n\u001b[0;32m--> 197\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_log(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mEpoch: \u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m}\u001b[39;00m\u001b[39m | Train Loss: \u001b[39m\u001b[39m{\u001b[39;00mtrain_metrics[\u001b[39m0\u001b[39m]\u001b[39m:\u001b[39;00m\u001b[39m.4f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m | Train Balanced Acc: \u001b[39m\u001b[39m{\u001b[39;00mtrain_metrics[\u001b[39m2\u001b[39m]\u001b[39m \u001b[39m\u001b[39m*\u001b[39m\u001b[39m \u001b[39m\u001b[39m100\u001b[39m\u001b[39m:\u001b[39;00m\u001b[39m.4f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m % | Val Loss: \u001b[39m\u001b[39m{\u001b[39;00mval_metrics[\u001b[39m0\u001b[39m]\u001b[39m:\u001b[39;00m\u001b[39m.4f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m | Val Balanced Acc: \u001b[39m\u001b[39m{\u001b[39;00mval_metrics[\u001b[39m2\u001b[39m]\u001b[39m \u001b[39m\u001b[39m*\u001b[39m\u001b[39m \u001b[39m\u001b[39m100\u001b[39m\u001b[39m:\u001b[39;00m\u001b[39m.4f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m % \u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    199\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlr_scheduler\u001b[39m.\u001b[39mstep()\n\u001b[1;32m    201\u001b[0m \u001b[39mif\u001b[39;00m (epoch \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m) \u001b[39m%\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msave_every \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "\u001b[0;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "main(train_dataloader, val_dataloader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vi_trans",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
