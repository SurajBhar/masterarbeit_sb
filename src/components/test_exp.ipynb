{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU device: Tesla V100-SXM2-32GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print('GPU device:',torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print('No GPU avaialable, Using CPU')\n",
    "\n",
    "torch.cuda.set_device(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sur06423/miniconda3/envs/vi_trans/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Standard Library Imports\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import logging\n",
    "import getpass\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "import random\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "\n",
    "# Third-Party Library Imports\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local Imports\n",
    "sys.path.append('/home/sur06423/hiwi/vit_exp/vision_tranformer_baseline')\n",
    "from src.components import data_setup\n",
    "from src.components.dataset import ImageFolderCustom\n",
    "from src.components import utils\n",
    "from src.components.config_manager_baseline import get_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_time(seconds):\n",
    "    \"\"\"Converts time in seconds to hours, minutes, and seconds format.\"\"\"\n",
    "    hours = seconds // 3600\n",
    "    minutes = (seconds % 3600) // 60\n",
    "    seconds = seconds % 60\n",
    "    return f\"{int(hours)} hours, {int(minutes)} minutes, {int(seconds)} seconds\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_balanced_accuracy(y_pred, y_true, num_classes, epsilon=1e-9):\n",
    "    \"\"\"\n",
    "    Calculates the balanced accuracy score.\n",
    "    \n",
    "    Args:\n",
    "        y_pred (torch.Tensor): Predicted labels.\n",
    "        y_true (torch.Tensor): True labels.\n",
    "        num_classes (int): Number of classes in the dataset.\n",
    "        epsilon (float): A small value to add to denominators to prevent division by zero.\n",
    "        \n",
    "    Returns:\n",
    "        float: Balanced accuracy score.\n",
    "    \"\"\"\n",
    "    # Create confusion matrix\n",
    "    confusion_matrix = torch.zeros(num_classes, num_classes, device=y_pred.device)\n",
    "    for t, p in zip(y_true.view(-1), y_pred.view(-1)):\n",
    "        confusion_matrix[t.long(), p.long()] += 1\n",
    "\n",
    "    # Calculate recall for each class, adding epsilon to avoid division by zero\n",
    "    # Recall =  dividing the true positives by the sum of the true positive and false negative for each class\n",
    "    # Recall = (diagonal elements of the confusion matrix) /  (the sum of elements in each row of the confusion matrix + epsilon)\n",
    "    recall = torch.diag(confusion_matrix) / (confusion_matrix.sum(1) + epsilon)\n",
    "\n",
    "    # balanced_accuracy_per_class = recall  # This line is technically not needed but added for clarity\n",
    "\n",
    "    # Calculate balanced accuracy\n",
    "    balanced_accuracy = recall.mean().item()\n",
    "\n",
    "    return balanced_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_and_create_dataloaders(batch_size, train_dir, val_dir, num_workers, prefetch_factor):\n",
    "    pretrained_vit_weights = torchvision.models.ViT_B_16_Weights.DEFAULT\n",
    "    pretrained_vit = torchvision.models.vit_b_16(weights=pretrained_vit_weights)\n",
    "\n",
    "    # Freeze the base parameters\n",
    "    for parameter in pretrained_vit.parameters():\n",
    "        parameter.requires_grad = False\n",
    "\n",
    "    # Change the classifier head\n",
    "    pretrained_vit.heads = nn.Linear(in_features=768, out_features=34)\n",
    "    pretrained_vit_transforms = pretrained_vit_weights.transforms()\n",
    "\n",
    "    train_dataloader, val_dataloader, class_names = data_setup.create_dataloaders(\n",
    "        train_dir=train_dir,\n",
    "        val_dir=val_dir,\n",
    "        transform=pretrained_vit_transforms,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=num_workers,\n",
    "        prefetch_factor=prefetch_factor\n",
    "    )\n",
    "\n",
    "    return train_dataloader, val_dataloader, class_names , pretrained_vit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_train_objs(model, num_epochs, optimizer_choice, scheduler_choice, initial_lr, momentum, weight_decay_adam, wd_sgd):\n",
    "    # Setup the optimizer\n",
    "    if optimizer_choice == 'ADAM':\n",
    "        optimizer = optim.Adam(\n",
    "            params=model.parameters(),\n",
    "            lr=initial_lr,\n",
    "            betas=(0.9, 0.999),\n",
    "            weight_decay=weight_decay_adam\n",
    "        )\n",
    "    elif optimizer_choice == 'SGD':\n",
    "        optimizer = optim.SGD(\n",
    "            params=model.parameters(),\n",
    "            lr=initial_lr,\n",
    "            momentum=momentum,\n",
    "            weight_decay=wd_sgd\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(\"Invalid optimizer choice. Choose 'adam' or 'sgd'.\")\n",
    "\n",
    "    # Define the lambda function for learning rate scheduling\n",
    "    def lr_lambda(epoch):\n",
    "        # Decrease the learning rate by a factor of 10 every 30 epochs\n",
    "        return 0.1 ** (epoch // 30)\n",
    "\n",
    "    # Setup the learning rate scheduler\n",
    "    if scheduler_choice == 'CosineAnnealingLR':\n",
    "        lr_scheduler = optim.lr_scheduler.CosineAnnealingLR(\n",
    "            optimizer,\n",
    "            T_max=num_epochs\n",
    "        )\n",
    "    elif scheduler_choice == 'LambdaLR':\n",
    "        lr_scheduler = optim.lr_scheduler.LambdaLR(\n",
    "            optimizer,\n",
    "            lr_lambda=lr_lambda  # Used the custom lambda function\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(\"Invalid scheduler choice. Choose 'LambdaLR' or 'CosineAnnealingLR'\")\n",
    "    \n",
    "    return optimizer, lr_scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step_sample_wise(gpu_id, model, train_dataloader, optimizer):\n",
    "    model.train()\n",
    "    y_pred_all = []\n",
    "    y_all = []\n",
    "    running_train_loss, train_acc, num_samples = 0, 0, 0\n",
    "    print(f\"In the beginning the value of running train loss is: {running_train_loss} , train accuracy is : {train_acc}, number of samples is: {num_samples}\")\n",
    "    for batch, (X, y) in enumerate(train_dataloader):\n",
    "        X, y = X.to(gpu_id), y.to(gpu_id)\n",
    "        print(f\"The shape of the image batch: {batch} , is : {X.size()}\")\n",
    "        print(f\"The shape of the ground truth batch : {batch} , is : {y.size()}\")\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(X)\n",
    "        print(f\"The shape of the predictions for batch: {batch} , is: {y_pred.size()}\")\n",
    "        loss = F.cross_entropy(y_pred, y)\n",
    "        print(f\"The calculated Loss value for batch: {batch} , is : {loss}\")\n",
    "        loss_sum = F.cross_entropy(y_pred, y, reduction='sum')\n",
    "        print(f\"The calculated Loss value as sum for batch: {batch} , is : {loss_sum}\")\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # F.cross_entropy returns the mean loss per batch, \n",
    "        # and we need the total loss to calculate the average loss over all samples after the loop.\n",
    "        running_train_loss += loss.item() * X.size(0)\n",
    "        y_pred_class = torch.argmax(torch.softmax(y_pred, dim=1), dim=1)\n",
    "        train_acc += (y_pred_class == y).type(torch.float).sum().item()\n",
    "        num_samples += X.size(0)\n",
    "        y_pred_all.append(y_pred_class)\n",
    "        y_all.append(y)\n",
    "\n",
    "        print(f\"After batch {batch} the value of running train loss is: {running_train_loss} , train accuracy is : {train_acc}, number of samples is: {num_samples}\")\n",
    "    avg_loss = running_train_loss / num_samples\n",
    "    # Average accuracy = Summation of Accuracy over all batches / Number of samples\n",
    "    avg_acc = train_acc / num_samples\n",
    "\n",
    "    before_lr_rate =  {optimizer.param_groups[0][\"lr\"]}\n",
    "\n",
    "    # Concatenate all the predictions and ground truths per epoch\n",
    "    train_y_pred_all = torch.concatenate(y_pred_all)\n",
    "    train_y_all = torch.concatenate(y_all)\n",
    "    return avg_loss, avg_acc, train_y_pred_all, train_y_all, before_lr_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_step_sample_wise(gpu_id, model, val_dataloader):\n",
    "    model.eval()\n",
    "    y_pred_all = []\n",
    "    y_all = []\n",
    "    running_val_loss, val_acc, num_samples = 0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        for batch, (X, y) in enumerate(val_dataloader):\n",
    "            X, y = X.to(gpu_id), y.to(gpu_id)\n",
    "            y_pred = model(X)\n",
    "            loss = F.cross_entropy(y_pred, y)\n",
    "            # F.cross_entropy returns the mean loss per batch, \n",
    "            # and we need the total loss to calculate the average loss over all samples after the loop.\n",
    "            running_val_loss += loss.item() * X.size(0)\n",
    "            y_pred_class = torch.argmax(torch.softmax(y_pred, dim=1), dim=1)\n",
    "            val_acc += (y_pred_class == y).type(torch.float).sum().item()\n",
    "            num_samples += X.size(0)\n",
    "            y_pred_all.append(y_pred_class)\n",
    "            y_all.append(y)\n",
    "            print(f\"After batch {batch} the value of running val loss is: {running_val_loss} , val accuracy is : {val_acc}, number of samples is: {num_samples}\")\n",
    "    \n",
    "    avg_loss = running_val_loss / num_samples\n",
    "    # Average accuracy = Summation of Accuracy over all batches / Number of samples\n",
    "    avg_acc = val_acc / num_samples\n",
    "\n",
    "    # Concatenate all the predictions and ground truths per epoch\n",
    "    val_y_pred_all = torch.concatenate(y_pred_all)\n",
    "    val_y_all = torch.concatenate(y_all)\n",
    "    return avg_loss, avg_acc, val_y_pred_all, val_y_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(max_epochs: int, num_classes: int, lr_scheduler, gpu_id, model, train_dataloader, optimizer, val_dataloader):\n",
    "    model = model.to(gpu_id)\n",
    "    total_start_time = time.time()  # Start time for the entire training and validation process\n",
    "    try:\n",
    "        start_epoch = 0\n",
    "        for epoch in tqdm(range(start_epoch, max_epochs)):\n",
    "            try:\n",
    "                ############### Training & Validation step Here ##########################\n",
    "                avg_train_loss, avg_train_acc, train_y_pred_all, train_y_all , before_lr_rate = train_step_sample_wise(gpu_id, model, train_dataloader, optimizer)\n",
    "                # Balanced accuracy per epoch\n",
    "                train_balanced_accuracy = calculate_balanced_accuracy(train_y_pred_all, train_y_all, num_classes)\n",
    "                # Explicitly release memory\n",
    "                del train_y_pred_all, train_y_all\n",
    "                print(f\"Epoch: {epoch} | Average train loss: {avg_train_loss} | Average train accuracy: {avg_train_acc} | Balanced Accuracy: {train_balanced_accuracy}\")\n",
    "                print(f\"Epoch: {epoch} | learning rate: {before_lr_rate}\" )\n",
    "                lr_scheduler.step()\n",
    "\n",
    "\n",
    "                avg_val_loss, avg_val_acc, val_y_pred_all, val_y_all= val_step_sample_wise(gpu_id, model, val_dataloader)\n",
    "                # Balanced accuracy per epoch\n",
    "                val_balanced_accuracy = calculate_balanced_accuracy(val_y_pred_all, val_y_all, num_classes)\n",
    "                # Explicitly release memory\n",
    "                del val_y_pred_all, val_y_all\n",
    "                print(f\"Epoch: {epoch} | Average val loss: {avg_val_loss} | Average val accuracy: {avg_val_acc} | Balanced Accuracy: {val_balanced_accuracy}\")\n",
    "\n",
    "\n",
    "            except RuntimeError as e:\n",
    "                print(f\"Runtime error occurred in epoch {epoch}: {e}\")\n",
    "                continue\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "\n",
    "    finally:\n",
    "        total_end_time = time.time()  # End time for the entire training and validation process\n",
    "        total_duration = total_end_time - total_start_time\n",
    "        formatted_duration = format_time(total_duration)\n",
    "        print(f\"Total training and validation time: {formatted_duration}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets\n",
    "\n",
    "def prepare_dataset():\n",
    "    pretrained_vit_weights = torchvision.models.ViT_B_16_Weights.DEFAULT\n",
    "    pretrained_vit = torchvision.models.vit_b_16(weights=pretrained_vit_weights)\n",
    "\n",
    "    # Freeze the base parameters\n",
    "    for parameter in pretrained_vit.parameters():\n",
    "        parameter.requires_grad = False\n",
    "\n",
    "    # Change the classifier head\n",
    "    pretrained_vit.heads = nn.Linear(in_features=768, out_features=3)\n",
    "    pretrained_vit_transforms = pretrained_vit_weights.transforms()\n",
    "    # Convert the string path to a Path object\n",
    "    image_path = Path(\"/home/sur06423/hiwi/vit_exp/vision_tranformer_baseline/src/ddp_code/data_pizza/pizza_steak_sushi\")\n",
    "    train_dir = image_path / \"train\"\n",
    "    test_dir = image_path / \"test\"\n",
    "    \n",
    "    # Use ImageFolder to create dataset(s)\n",
    "    train_dataset = datasets.ImageFolder(str(train_dir), transform=pretrained_vit_transforms)\n",
    "    val_dataset = datasets.ImageFolder(str(test_dir), transform=pretrained_vit_transforms)\n",
    "\n",
    "    # Get class names\n",
    "    class_names = train_dataset.classes\n",
    "\n",
    "    return train_dataset, val_dataset, class_names, pretrained_vit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataloader(dataset: Dataset, batch_size: int, num_workers, prefetch_factor):\n",
    "    return DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True,\n",
    "        shuffle=False,\n",
    "        drop_last = False,\n",
    "        prefetch_factor = prefetch_factor\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here you can change things for experimentation\n",
    "batch_size = 64\n",
    "prefetch_factor = 2\n",
    "num_epochs = 10\n",
    "\n",
    "optimizer = 'SGD'\n",
    "scheduler = 'CosineAnnealingLR'\n",
    "lr = 0.001\n",
    "momentum = 0.9\n",
    "weight_decay = 0.0001\n",
    "w_decay_adam = 0.03\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    torch.cuda.set_device(0)\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print('No GPU avaialable, Using CPU')\n",
    "\n",
    "# device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "utils.set_seeds(1)\n",
    "num_workers = os.cpu_count()\n",
    "\n",
    "train_dataset, val_dataset, class_names, pretrained_vit = prepare_dataset()\n",
    "train_dataloader = prepare_dataloader(dataset= train_dataset, batch_size = batch_size, num_workers = num_workers, prefetch_factor = prefetch_factor)\n",
    "val_dataloader = prepare_dataloader(dataset= val_dataset, batch_size = batch_size, num_workers = num_workers, prefetch_factor = prefetch_factor)\n",
    "\n",
    "optimizer, lr_scheduler = load_train_objs(pretrained_vit, \n",
    "                                            num_epochs, \n",
    "                                            optimizer, \n",
    "                                            scheduler, \n",
    "                                            lr, \n",
    "                                            momentum, \n",
    "                                            w_decay_adam, \n",
    "                                            weight_decay\n",
    "                                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225\n",
      "4\n",
      "75\n",
      "2\n",
      "64\n"
     ]
    }
   ],
   "source": [
    "print(len(train_dataloader.dataset))\n",
    "print(len(train_dataloader))\n",
    "print(len(val_dataloader.dataset))\n",
    "print(len(val_dataloader))\n",
    "print(train_dataloader.batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the beginning the value of running train loss is: 0 , train accuracy is : 0, number of samples is: 0\n",
      "The shape of the image batch: 0 , is : torch.Size([64, 3, 224, 224])\n",
      "The shape of the ground truth batch : 0 , is : torch.Size([64])\n",
      "The shape of the predictions for batch: 0 , is: torch.Size([64, 3])\n",
      "The calculated Loss value for batch: 0 , is : 0.35381051898002625\n",
      "The calculated Loss value as sum for batch: 0 , is : 22.64387321472168\n",
      "After batch 0 the value of running train loss is: 22.64387321472168 , train accuracy is : 57.0, number of samples is: 64\n",
      "The shape of the image batch: 1 , is : torch.Size([64, 3, 224, 224])\n",
      "The shape of the ground truth batch : 1 , is : torch.Size([64])\n",
      "The shape of the predictions for batch: 1 , is: torch.Size([64, 3])\n",
      "The calculated Loss value for batch: 1 , is : 0.4343680441379547\n",
      "The calculated Loss value as sum for batch: 1 , is : 27.7995548248291\n",
      "After batch 1 the value of running train loss is: 50.44342803955078 , train accuracy is : 114.0, number of samples is: 128\n",
      "The shape of the image batch: 2 , is : torch.Size([64, 3, 224, 224])\n",
      "The shape of the ground truth batch : 2 , is : torch.Size([64])\n",
      "The shape of the predictions for batch: 2 , is: torch.Size([64, 3])\n",
      "The calculated Loss value for batch: 2 , is : 0.33890315890312195\n",
      "The calculated Loss value as sum for batch: 2 , is : 21.689802169799805\n",
      "After batch 2 the value of running train loss is: 72.13323020935059 , train accuracy is : 176.0, number of samples is: 192\n",
      "The shape of the image batch: 3 , is : torch.Size([33, 3, 224, 224])\n",
      "The shape of the ground truth batch : 3 , is : torch.Size([33])\n",
      "The shape of the predictions for batch: 3 , is: torch.Size([33, 3])\n",
      "The calculated Loss value for batch: 3 , is : 0.2778818607330322\n",
      "The calculated Loss value as sum for batch: 3 , is : 9.170101165771484\n",
      "After batch 3 the value of running train loss is: 81.30333161354065 , train accuracy is : 209.0, number of samples is: 225\n",
      "Epoch: 0 | Average train loss: 0.3613481405046251 | Average train accuracy: 0.9288888888888889 | Balanced Accuracy: 0.9299003481864929\n",
      "Epoch: 0 | learning rate: {0.0005}\n",
      "After batch 0 the value of running val loss is: 19.447906494140625 , val accuracy is : 60.0, number of samples is: 64\n",
      "After batch 1 the value of running val loss is: 23.372226119041443 , val accuracy is : 69.0, number of samples is: 75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [00:10<00:10, 10.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | Average val loss: 0.31162968158721926 | Average val accuracy: 0.92 | Balanced Accuracy: 0.912529706954956\n",
      "In the beginning the value of running train loss is: 0 , train accuracy is : 0, number of samples is: 0\n",
      "The shape of the image batch: 0 , is : torch.Size([64, 3, 224, 224])\n",
      "The shape of the ground truth batch : 0 , is : torch.Size([64])\n",
      "The shape of the predictions for batch: 0 , is: torch.Size([64, 3])\n",
      "The calculated Loss value for batch: 0 , is : 0.3277164697647095\n",
      "The calculated Loss value as sum for batch: 0 , is : 20.973854064941406\n",
      "After batch 0 the value of running train loss is: 20.973854064941406 , train accuracy is : 57.0, number of samples is: 64\n",
      "The shape of the image batch: 1 , is : torch.Size([64, 3, 224, 224])\n",
      "The shape of the ground truth batch : 1 , is : torch.Size([64])\n",
      "The shape of the predictions for batch: 1 , is: torch.Size([64, 3])\n",
      "The calculated Loss value for batch: 1 , is : 0.3945465087890625\n",
      "The calculated Loss value as sum for batch: 1 , is : 25.2509765625\n",
      "After batch 1 the value of running train loss is: 46.224830627441406 , train accuracy is : 115.0, number of samples is: 128\n",
      "The shape of the image batch: 2 , is : torch.Size([64, 3, 224, 224])\n",
      "The shape of the ground truth batch : 2 , is : torch.Size([64])\n",
      "The shape of the predictions for batch: 2 , is: torch.Size([64, 3])\n",
      "The calculated Loss value for batch: 2 , is : 0.3096557557582855\n",
      "The calculated Loss value as sum for batch: 2 , is : 19.817968368530273\n",
      "After batch 2 the value of running train loss is: 66.04279899597168 , train accuracy is : 177.0, number of samples is: 192\n",
      "The shape of the image batch: 3 , is : torch.Size([33, 3, 224, 224])\n",
      "The shape of the ground truth batch : 3 , is : torch.Size([33])\n",
      "The shape of the predictions for batch: 3 , is: torch.Size([33, 3])\n",
      "The calculated Loss value for batch: 3 , is : 0.257764995098114\n",
      "The calculated Loss value as sum for batch: 3 , is : 8.506244659423828\n",
      "After batch 3 the value of running train loss is: 74.54904383420944 , train accuracy is : 210.0, number of samples is: 225\n",
      "Epoch: 1 | Average train loss: 0.3313290837075975 | Average train accuracy: 0.9333333333333333 | Balanced Accuracy: 0.9343447685241699\n",
      "Epoch: 1 | learning rate: {0.00034549150281252633}\n",
      "After batch 0 the value of running val loss is: 18.325998306274414 , val accuracy is : 60.0, number of samples is: 64\n",
      "After batch 1 the value of running val loss is: 22.167652785778046 , val accuracy is : 69.0, number of samples is: 75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:20<00:00, 10.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | Average val loss: 0.2955687038103739 | Average val accuracy: 0.92 | Balanced Accuracy: 0.912529706954956\n",
      "Total training and validation time: 0 hours, 0 minutes, 20 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "training(max_epochs = 2, \n",
    "         num_classes = 3, \n",
    "         lr_scheduler= lr_scheduler,  \n",
    "         gpu_id = device, \n",
    "         model= pretrained_vit, \n",
    "         train_dataloader= train_dataloader, \n",
    "         optimizer = optimizer, \n",
    "         val_dataloader = val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here you can change things for experimentation\n",
    "experiment_name = \"Exp_01_SGD_Sp_1\"\n",
    "#device = 0\n",
    "\n",
    "num_workers = 20\n",
    "batch_size = 1024\n",
    "prefetch_factor = 2\n",
    "\n",
    "train_dir = \"/net/polaris/storage/deeplearning/sur_data/rgb_daa/split_1/train\"\n",
    "val_dir = \"/net/polaris/storage/deeplearning/sur_data/rgb_daa/split_1/val\"\n",
    "num_epochs = 10\n",
    "\n",
    "optimizer = 'SGD'\n",
    "scheduler = 'CosineAnnealingLR'\n",
    "batch_size = 1024\n",
    "lr = 0.001\n",
    "momentum = 0.9\n",
    "weight_decay = 0.0001\n",
    "w_decay_adam = 0.03\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    torch.cuda.set_device(0)\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print('No GPU avaialable, Using CPU')\n",
    "\n",
    "# device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "utils.set_seeds(1)\n",
    "num_workers = os.cpu_count()\n",
    "train_dataloader, val_dataloader, _, model_vit = setup_and_create_dataloaders(batch_size, \n",
    "                                                                                train_dir, \n",
    "                                                                                val_dir, \n",
    "                                                                                num_workers, \n",
    "                                                                                prefetch_factor,\n",
    "                                                                            )\n",
    "optimizer, lr_scheduler = load_train_objs(model_vit, \n",
    "                                            num_epochs, \n",
    "                                            optimizer, \n",
    "                                            scheduler, \n",
    "                                            lr, \n",
    "                                            momentum, \n",
    "                                            w_decay_adam, \n",
    "                                            weight_decay\n",
    "                                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU device: Tesla V100-SXM2-32GB\n"
     ]
    }
   ],
   "source": [
    "print('GPU device:',torch.cuda.get_device_name(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "279\n"
     ]
    }
   ],
   "source": [
    "print(len(train_dataloader))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "284807\n"
     ]
    }
   ],
   "source": [
    "print(len(train_dataloader.dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54541\n"
     ]
    }
   ],
   "source": [
    "print(len(val_dataloader.dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54\n"
     ]
    }
   ],
   "source": [
    "print(len(val_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vi_trans",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
