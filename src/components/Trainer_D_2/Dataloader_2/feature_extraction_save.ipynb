{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print('GPU device:',torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print('No GPU avaialable, Using CPU')\n",
    "\n",
    "torch.cuda.set_device(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.device_count() > 1:\n",
    "    print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seeds\n",
    "def set_seeds(seed: int=42):\n",
    "    \"\"\"Sets random sets for torch operations.\n",
    "\n",
    "    Args:\n",
    "        seed (int, optional): Random seed to set. Defaults to 42.\n",
    "    \"\"\"\n",
    "    # Set the seed for general torch operations\n",
    "    torch.manual_seed(seed)\n",
    "    # Set the seed for CUDA torch operations (ones that happen on the GPU)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "\n",
    "set_seeds(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "import sys\n",
    "\n",
    "def setup_ccname():\n",
    "    user=getpass.getuser()\n",
    "    # check if k5start is running, exit otherwise\n",
    "    try:\n",
    "        pid=open(\"/tmp/k5pid_\"+user).read().strip()\n",
    "        os.kill(int(pid), 0)\n",
    "    except:\n",
    "        sys.stderr.write(\"Unable to setup KRB5CCNAME!\\nk5start not running!\\n\")\n",
    "        sys.exit(1)\n",
    "    try:\n",
    "        ccname=open(\"/tmp/kccache_\"+user).read().split(\"=\")[1].strip()\n",
    "        os.environ['KRB5CCNAME']=ccname\n",
    "    except:\n",
    "        sys.stderr.write(\"Unable to setup KRB5CCNAME!\\nmaybe k5start not running?\\n\")\n",
    "        sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "from typing import List, Dict\n",
    "\n",
    "class CustomImageDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Custom dataset for loading image data from a directory.\n",
    "\n",
    "    Args:\n",
    "        root_dir (str): Root directory containing class subdirectories.\n",
    "        transform (callable, optional): A function/transform to apply to the image.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, root_dir: str, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.classes, self.class_to_idx = self._find_classes(root_dir)\n",
    "        self.samples = self._load_samples()\n",
    "        self.class_ratios = self._calculate_class_ratios()\n",
    "\n",
    "    def _find_classes(self, directory: str) -> (List[str], Dict[str, int]):\n",
    "        classes = [d.name for d in os.scandir(directory) if d.is_dir()]\n",
    "        classes.sort()\n",
    "        class_to_idx = {cls_name: i for i, cls_name in enumerate(classes)}\n",
    "        return classes, class_to_idx\n",
    "\n",
    "    def _load_samples(self):\n",
    "        samples = []\n",
    "        for target_class in self.classes:\n",
    "            class_dir = os.path.join(self.root_dir, target_class)\n",
    "            class_idx = self.class_to_idx[target_class]\n",
    "            for root, _, fnames in os.walk(class_dir):\n",
    "                for fname in fnames:\n",
    "                    path = os.path.join(root, fname)\n",
    "                    samples.append((path, class_idx))\n",
    "        return samples\n",
    "\n",
    "    def _calculate_class_ratios(self):\n",
    "        class_counts = [0] * len(self.classes)\n",
    "        for _, class_idx in self.samples:\n",
    "            class_counts[class_idx] += 1\n",
    "\n",
    "        total_samples = len(self.samples)\n",
    "        class_ratios = [count / total_samples for count in class_counts]\n",
    "\n",
    "        return class_ratios\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path, target = self.samples[idx]\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return img, target, img_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import timm\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "# Load the pretrained ViT model\n",
    "model = timm.create_model(\n",
    "    'vit_huge_patch14_224.orig_in21k',\n",
    "    pretrained=True,\n",
    "    num_classes=0,  # remove classifier nn.Linear\n",
    ")\n",
    "model = model.eval()\n",
    "model = model.to(device)\n",
    "# Create data transforms\n",
    "data_config = timm.data.resolve_model_data_config(model)\n",
    "data_transforms = timm.data.create_transform(**data_config, is_training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a CustomImageDataset instance\n",
    "dataset = CustomImageDataset(root_dir='/net/polaris/storage/deeplearning/sur_data/rgb_daa/split_1/train', \n",
    "                             transform=data_transforms\n",
    "                             )\n",
    "\n",
    "# Create a DataLoader with custom collate_fn\n",
    "dataloader = DataLoader(dataset, \n",
    "                        batch_size=1024, \n",
    "                        shuffle=True,\n",
    "                        num_workers=16, \n",
    "                        #collate_fn=custom_collate,\n",
    "                        drop_last=False,\n",
    "                        )\n",
    "\n",
    "# Calculate the total number of batches\n",
    "total_batches = len(dataloader)\n",
    "total_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import pickle\n",
    "\n",
    "# Initialize a list to accumulate features\n",
    "all_features = []\n",
    "all_gt_labels = []\n",
    "img_paths_batchwise = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(dataloader, total=len(dataloader)):\n",
    "        setup_ccname()\n",
    "        images, targets, img_paths = batch\n",
    "        images = images.to(device)\n",
    "        features = model(images)\n",
    "        features = features.to('cpu')\n",
    "        all_features.append(features)\n",
    "        all_gt_labels.append(targets)\n",
    "        img_paths_batchwise.append(img_paths)\n",
    "\n",
    "# Collect features\n",
    "all_features = torch.cat(all_features, dim=0)\n",
    "all_gt_labels = torch.cat(all_gt_labels, dim=0)\n",
    "\n",
    "# Save features_all as a list in pickle format ::: Change names in the paths\n",
    "with open('/home/sur06423/hiwi/vit_exp/vision_tranformer_baseline/src/components/Trainer_D_2/Dataloader_2/features_store/rgb_split_1_daa/all_d2_s1_features.pkl', 'wb') as file:\n",
    "    pickle.dump(all_features, file)\n",
    "\n",
    "with open('/home/sur06423/hiwi/vit_exp/vision_tranformer_baseline/src/components/Trainer_D_2/Dataloader_2/features_store/rgb_split_1_daa/all_d2_s1_labels.pkl', 'wb') as file:\n",
    "    pickle.dump(all_gt_labels, file)\n",
    "\n",
    "all_img_paths = img_paths_batchwise\n",
    "with open('/home/sur06423/hiwi/vit_exp/vision_tranformer_baseline/src/components/Trainer_D_2/Dataloader_2/features_store/rgb_split_1_daa/all_d2_s1_imagepaths.pkl', 'wb') as file:\n",
    "    pickle.dump(all_img_paths, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# Load features_all as a list \n",
    "with open('/home/sur06423/hiwi/vit_exp/vision_tranformer_baseline/src/components/Trainer_D_2/Dataloader_2/features_store/rgb_split_1_daa/all_d2_s1_features.pkl', 'rb') as file:\n",
    "    all_features_loaded = pickle.load(file)\n",
    "\n",
    "with open('/home/sur06423/hiwi/vit_exp/vision_tranformer_baseline/src/components/Trainer_D_2/Dataloader_2/features_store/rgb_split_1_daa/all_d2_s1_labels.pkl', 'rb') as file:\n",
    "    all_gt_labels_loaded = pickle.load(file)\n",
    "\n",
    "with open('/home/sur06423/hiwi/vit_exp/vision_tranformer_baseline/src/components/Trainer_D_2/Dataloader_2/features_store/rgb_split_1_daa/all_d2_s1_imagepaths.pkl', 'rb') as file:\n",
    "    all_img_paths_loaded = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features_loaded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_gt_labels_loaded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_img_paths_loaded.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_in_dataset = dataset.classes\n",
    "print(f\"The class with 8th index in the DAA Image split_1 train dataset are:{classes_in_dataset[8]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "first_path = all_img_paths_loaded[0][0]\n",
    "img = Image.open(first_path)\n",
    "img"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vi_trans",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
