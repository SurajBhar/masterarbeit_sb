{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from scipy.stats import cumfreq\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from scipy.stats import entropy\n",
    "from collections import Counter\n",
    "\n",
    "from b_weightedimagedataset import WeightedImageDataset\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import hdbscan\n",
    "\n",
    "\n",
    "CATEGORY_MAPPING = {\n",
    "    '_non_distracted': 0, 'distracted': 1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define file paths and parameters\n",
    "feature_file_path = '/home/sur06423/hiwi/vit_exp/vision_tranformer_baseline/src/components/distraction_detection_d_b/clustering_experiments/features_split_0_kinect_rgb/all_split_0_rgb_features.pkl'\n",
    "label_file_path = '/home/sur06423/hiwi/vit_exp/vision_tranformer_baseline/src/components/distraction_detection_d_b/clustering_experiments/features_split_0_kinect_rgb/all_split_0_rgb_labels.pkl'\n",
    "img_path_file_path = '/home/sur06423/hiwi/vit_exp/vision_tranformer_baseline/src/components/distraction_detection_d_b/clustering_experiments/features_split_0_kinect_rgb/all_split_0_rgb_imagepaths.pkl'\n",
    "num_categories = 2\n",
    "batch_size = 1024\n",
    "save_path = '/home/sur06423/hiwi/vit_exp/vision_tranformer_baseline/src/components/distraction_detection_d_b/KL_results'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(feature_file_path, label_file_path, img_path_file_path):\n",
    "    with open(feature_file_path, 'rb') as file:\n",
    "        features = pickle.load(file)\n",
    "    with open(label_file_path, 'rb') as file:\n",
    "        labels = pickle.load(file)\n",
    "    with open(img_path_file_path, 'rb') as file:\n",
    "        img_paths = pickle.load(file)\n",
    "    return features, labels, img_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "features, labels, img_paths = load_data(feature_file_path, label_file_path, img_path_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The size of RGB Kinect DAA dataset (split_0) is 259865"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "259865"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Each extracted feature corresponds to a size of 1280"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1280"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(features[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "259865"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# There are 254 batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "254"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(img_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All batches contain 1024 images except last batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1024"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(img_paths[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Last Batch Contains Only 793 Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "793"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(img_paths[253])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch conversion of precomputed features, Batches = 254, Batch Size 1024, Feature size: [1,1280]\n",
    "features_loader = [features[i:i+1024] for i in range(0, len(features), 1024)]\n",
    "gt_labels_loader = [labels[i:i+1024] for i in range(0, len(labels), 1024)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "254"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(features_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "793"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(features_loader[253])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment : Outliers weight = 0.02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from b_weightedimagedataset import WeightedImageDataset\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import hdbscan\n",
    "\n",
    "import os\n",
    "import getpass\n",
    "import sys\n",
    "\n",
    "def setup_ccname():\n",
    "    user=getpass.getuser()\n",
    "    # check if k5start is running, exit otherwise\n",
    "    try:\n",
    "        pid=open(\"/tmp/k5pid_\"+user).read().strip()\n",
    "        os.kill(int(pid), 0)\n",
    "    except:\n",
    "        sys.stderr.write(\"Unable to setup KRB5CCNAME!\\nk5start not running!\\n\")\n",
    "        sys.exit(1)\n",
    "    try:\n",
    "        ccname=open(\"/tmp/kccache_\"+user).read().split(\"=\")[1].strip()\n",
    "        os.environ['KRB5CCNAME']=ccname\n",
    "    except:\n",
    "        sys.stderr.write(\"Unable to setup KRB5CCNAME!\\nmaybe k5start not running?\\n\")\n",
    "        sys.exit(1)\n",
    "\n",
    "class DataLoaderEpochsCalculation:\n",
    "    def __init__(self, feature_file_path, label_file_path, img_path_file_path, num_categories, batch_size):\n",
    "        self.batch_size = batch_size\n",
    "        self.num_categories = num_categories\n",
    "        self.features, self.labels, self.img_paths_list = self.load_data(feature_file_path, label_file_path, img_path_file_path)\n",
    "        self.image_paths_all = [path for sublist in self.img_paths_list for path in sublist]\n",
    "        self.dataloader_b, self.weights_list, self.all_labels, self.all_cluster_counts = self.initialize_dataloaders()\n",
    "\n",
    "    def load_data(self, feature_file_path, label_file_path, img_path_file_path):\n",
    "        with open(feature_file_path, 'rb') as file:\n",
    "            features = pickle.load(file)\n",
    "        with open(label_file_path, 'rb') as file:\n",
    "            labels = pickle.load(file)\n",
    "        with open(img_path_file_path, 'rb') as file:\n",
    "            img_paths = pickle.load(file)\n",
    "        return features, labels, img_paths\n",
    "\n",
    "    def initialize_dataloaders(self):\n",
    "        # Batch conversion of precomputed features, Batches = 254, Batch Size 1024, Feature size: [1,1280]\n",
    "        features_loader = [self.features[i:i+1024] for i in range(0, len(self.features), 1024)]\n",
    "        gt_labels_loader = [self.labels[i:i+1024] for i in range(0, len(self.labels), 1024)]\n",
    "\n",
    "        # Get the weights\n",
    "        weights_list, all_labels, all_cluster_counts = self.process_batches(features_loader)\n",
    "        dataset_b = WeightedImageDataset(self.img_paths_list, weights_list, gt_labels_loader)\n",
    "        sampler_b = WeightedRandomSampler(dataset_b.weights, num_samples=len(dataset_b.weights), replacement=True)\n",
    "        dataloader_b = DataLoader(dataset_b, batch_size=self.batch_size, sampler=sampler_b, num_workers=10)\n",
    "\n",
    "        return dataloader_b, weights_list, all_labels, all_cluster_counts\n",
    "\n",
    "    def compute_weights_cosine_dist(self, features):\n",
    "        cosine_dist_matrix = 1 - cosine_similarity(features).astype(np.float64)\n",
    "        # Using Updated HDBSCAN for clustering with tuned Hyperparameters\n",
    "        clusterer = hdbscan.HDBSCAN(min_cluster_size=25, \n",
    "                                    min_samples=1, \n",
    "                                    cluster_selection_epsilon=0.0, \n",
    "                                    metric='precomputed', \n",
    "                                    cluster_selection_method='eom', \n",
    "                                    allow_single_cluster=False)\n",
    "        # clusterer = hdbscan.HDBSCAN(min_cluster_size=2, metric='precomputed', cluster_selection_method='eom')\n",
    "        labels = clusterer.fit_predict(cosine_dist_matrix)\n",
    "\n",
    "        weights = np.zeros_like(labels, dtype=float)\n",
    "        unique_labels = np.unique(labels)\n",
    "        noise_label = -1\n",
    "        # Initialize variables for managing the new outlier clusters\n",
    "        max_label = labels.max()\n",
    "        current_outlier_cluster_label = max_label + 1\n",
    "        outlier_cluster_count = 0\n",
    "\n",
    "        for label in unique_labels:\n",
    "            if label == noise_label:\n",
    "                # Process each noise point\n",
    "                for noise_index in np.where(labels == noise_label)[0]:\n",
    "                    # Assign it to the current outlier cluster\n",
    "                    labels[noise_index] = current_outlier_cluster_label\n",
    "                    outlier_cluster_count += 1\n",
    "                    weights[noise_index] = 0.02  # Assign weight as 0.02 Exp9\n",
    "\n",
    "                    # If the outlier cluster reaches its max size, move to a new one\n",
    "                    if outlier_cluster_count >= 50:\n",
    "                        current_outlier_cluster_label += 1\n",
    "                        outlier_cluster_count = 0\n",
    "            else:\n",
    "                # For non-noise points, distribute weights evenly within clusters\n",
    "                indices = np.where(labels == label)[0]\n",
    "                weights[indices] = 1.0 / len(indices)\n",
    "\n",
    "        total_clusters = len(np.unique(labels)) - 1  # Exclude the original noise label\n",
    "\n",
    "        return weights, labels, total_clusters\n",
    "\n",
    "    def process_batches(self, dataloader):\n",
    "        all_weights = []\n",
    "        all_labels = []\n",
    "        all_cluster_counts = []\n",
    "        for batch_features in dataloader:\n",
    "            weights, labels, total_clusters = self.compute_weights_cosine_dist(batch_features)\n",
    "            all_weights.append(weights)\n",
    "            all_labels.append(labels)\n",
    "            all_cluster_counts.append(total_clusters)\n",
    "\n",
    "        return all_weights, all_labels, all_cluster_counts\n",
    "    \n",
    "    ##############################################################################\n",
    "\n",
    "    def calculate_epochs_to_see_all_samples(self, dataloader, total_unique_samples):\n",
    "        unique_samples_seen = set()\n",
    "        unique_counts_per_epoch = []  # List to store counts after each epoch\n",
    "        epochs = 0\n",
    "        while len(unique_samples_seen) < total_unique_samples:\n",
    "            setup_ccname()\n",
    "            for _, _, _, paths in dataloader:\n",
    "                unique_samples_seen.update(paths)\n",
    "            unique_counts_per_epoch.append(len(unique_samples_seen))  # Store the count\n",
    "            print(f'After epoch {epochs}, unique samples seen: {len(unique_samples_seen)}')\n",
    "\n",
    "            # Call setup_ccname at epoch 0 and then every 15 epochs\n",
    "            #if epochs == 0 or (epochs % 10 == 0 and epochs != 0):\n",
    "            #    setup_ccname()\n",
    "\n",
    "            epochs += 1\n",
    "\n",
    "            if epochs > 1000:  # Safety check to avoid infinite loop\n",
    "                break\n",
    "\n",
    "        # Plot the results\n",
    "        self.plot_unique_samples_per_epoch(unique_counts_per_epoch, epochs)\n",
    "\n",
    "        return epochs\n",
    "    \n",
    "    def plot_unique_samples_per_epoch(self, unique_counts_per_epoch, epochs):\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(range(1, epochs + 1), unique_counts_per_epoch, marker='o')\n",
    "        plt.title('Unique Samples Seen Over Epochs')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Cumulative Unique Samples Seen')\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "\n",
    "    ################### Save the Results ######################################\n",
    "\n",
    "    def save_results_to_pickle(self, data, file_name):\n",
    "        with open(file_name, 'wb') as file:\n",
    "            pickle.dump(data, file)\n",
    "\n",
    "    def loop_dataloader_and_save(self, save_path):\n",
    "        # Calculate the number of epochs to see all unique samples\n",
    "        total_unique_samples = len(set(self.image_paths_all))  # all image paths are unique\n",
    "        print(f\"Calculating Total Epochs needed to see all :{total_unique_samples} image samples.\")\n",
    "        epochs_needed = self.calculate_epochs_to_see_all_samples(self.dataloader_b, total_unique_samples)\n",
    "        \n",
    "        # Save the result\n",
    "        self.save_results_to_pickle(epochs_needed, f'{save_path}/epochs_needed.pkl')\n",
    "        self.save_results_to_pickle(self.weights_list, f'{save_path}/weights_list_dataloader_b.pkl')\n",
    "\n",
    "        return epochs_needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define file paths and parameters\n",
    "feature_file_path = '/home/sur06423/hiwi/vit_exp/vision_tranformer_baseline/src/components/distraction_detection_d_b/clustering_experiments/features_split_0_kinect_rgb/all_split_0_rgb_features.pkl'\n",
    "label_file_path = '/home/sur06423/hiwi/vit_exp/vision_tranformer_baseline/src/components/distraction_detection_d_b/clustering_experiments/features_split_0_kinect_rgb/all_split_0_rgb_labels.pkl'\n",
    "img_path_file_path = '/home/sur06423/hiwi/vit_exp/vision_tranformer_baseline/src/components/distraction_detection_d_b/clustering_experiments/features_split_0_kinect_rgb/all_split_0_rgb_imagepaths.pkl'\n",
    "num_categories = 2\n",
    "batch_size = 1024\n",
    "save_path = '/home/sur06423/hiwi/vit_exp/vision_tranformer_baseline/src/components/distraction_detection_d_b'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Total Epochs needed to see all :259865 image samples.\n",
      "After epoch 0, unique samples seen: 158865\n",
      "After epoch 1, unique samples seen: 216403\n",
      "After epoch 2, unique samples seen: 239527\n",
      "After epoch 3, unique samples seen: 249328\n",
      "After epoch 4, unique samples seen: 253882\n",
      "After epoch 5, unique samples seen: 256088\n",
      "After epoch 6, unique samples seen: 257227\n",
      "After epoch 7, unique samples seen: 257906\n",
      "After epoch 8, unique samples seen: 258319\n",
      "After epoch 9, unique samples seen: 258584\n",
      "After epoch 10, unique samples seen: 258764\n",
      "After epoch 11, unique samples seen: 258915\n",
      "After epoch 12, unique samples seen: 259022\n",
      "After epoch 13, unique samples seen: 259091\n",
      "After epoch 14, unique samples seen: 259171\n",
      "After epoch 15, unique samples seen: 259248\n",
      "After epoch 16, unique samples seen: 259293\n",
      "After epoch 17, unique samples seen: 259347\n",
      "After epoch 18, unique samples seen: 259385\n",
      "After epoch 19, unique samples seen: 259415\n",
      "After epoch 20, unique samples seen: 259445\n",
      "After epoch 21, unique samples seen: 259470\n",
      "After epoch 22, unique samples seen: 259492\n",
      "After epoch 23, unique samples seen: 259517\n",
      "After epoch 24, unique samples seen: 259535\n",
      "After epoch 25, unique samples seen: 259562\n",
      "After epoch 26, unique samples seen: 259587\n",
      "After epoch 27, unique samples seen: 259603\n",
      "After epoch 28, unique samples seen: 259628\n",
      "After epoch 29, unique samples seen: 259638\n",
      "After epoch 30, unique samples seen: 259648\n",
      "After epoch 31, unique samples seen: 259663\n",
      "After epoch 32, unique samples seen: 259673\n",
      "After epoch 33, unique samples seen: 259683\n",
      "After epoch 34, unique samples seen: 259691\n",
      "After epoch 35, unique samples seen: 259704\n",
      "After epoch 36, unique samples seen: 259715\n",
      "After epoch 37, unique samples seen: 259726\n",
      "After epoch 38, unique samples seen: 259739\n",
      "After epoch 39, unique samples seen: 259746\n",
      "After epoch 40, unique samples seen: 259752\n",
      "After epoch 41, unique samples seen: 259765\n",
      "After epoch 42, unique samples seen: 259769\n",
      "After epoch 43, unique samples seen: 259780\n",
      "After epoch 44, unique samples seen: 259783\n",
      "After epoch 45, unique samples seen: 259791\n",
      "After epoch 46, unique samples seen: 259797\n",
      "After epoch 47, unique samples seen: 259802\n",
      "After epoch 48, unique samples seen: 259805\n",
      "After epoch 49, unique samples seen: 259808\n",
      "After epoch 50, unique samples seen: 259809\n",
      "After epoch 51, unique samples seen: 259812\n",
      "After epoch 52, unique samples seen: 259812\n",
      "After epoch 53, unique samples seen: 259817\n",
      "After epoch 54, unique samples seen: 259824\n",
      "After epoch 55, unique samples seen: 259828\n",
      "After epoch 56, unique samples seen: 259831\n",
      "After epoch 57, unique samples seen: 259834\n",
      "After epoch 58, unique samples seen: 259837\n",
      "After epoch 59, unique samples seen: 259837\n",
      "After epoch 60, unique samples seen: 259838\n",
      "After epoch 61, unique samples seen: 259840\n",
      "After epoch 62, unique samples seen: 259843\n",
      "After epoch 63, unique samples seen: 259844\n",
      "After epoch 64, unique samples seen: 259845\n",
      "After epoch 65, unique samples seen: 259846\n",
      "After epoch 66, unique samples seen: 259850\n",
      "After epoch 67, unique samples seen: 259851\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Created an instance of DataLoaderEpochsCalculation and performed the comparison\u001b[39;00m\n\u001b[1;32m      2\u001b[0m epoch_dataloader_b \u001b[38;5;241m=\u001b[39m DataLoaderEpochsCalculation(feature_file_path, label_file_path, img_path_file_path, num_categories, batch_size)\n\u001b[0;32m----> 3\u001b[0m epochs_needed_b \u001b[38;5;241m=\u001b[39m \u001b[43mepoch_dataloader_b\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloop_dataloader_and_save\u001b[49m\u001b[43m(\u001b[49m\u001b[43msave_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpochs needed to see all samples:\u001b[39m\u001b[38;5;124m\"\u001b[39m, epochs_needed_b)\n",
      "Cell \u001b[0;32mIn[14], line 161\u001b[0m, in \u001b[0;36mDataLoaderEpochsCalculation.loop_dataloader_and_save\u001b[0;34m(self, save_path)\u001b[0m\n\u001b[1;32m    159\u001b[0m total_unique_samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mset\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimage_paths_all))  \u001b[38;5;66;03m# all image paths are unique\u001b[39;00m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCalculating Total Epochs needed to see all :\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtotal_unique_samples\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m image samples.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 161\u001b[0m epochs_needed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcalculate_epochs_to_see_all_samples\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataloader_b\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal_unique_samples\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;66;03m# Save the result\u001b[39;00m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_results_to_pickle(epochs_needed, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msave_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/epochs_needed.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[14], line 123\u001b[0m, in \u001b[0;36mDataLoaderEpochsCalculation.calculate_epochs_to_see_all_samples\u001b[0;34m(self, dataloader, total_unique_samples)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(unique_samples_seen) \u001b[38;5;241m<\u001b[39m total_unique_samples:\n\u001b[1;32m    122\u001b[0m     setup_ccname()\n\u001b[0;32m--> 123\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _, _, _, paths \u001b[38;5;129;01min\u001b[39;00m dataloader:\n\u001b[1;32m    124\u001b[0m         unique_samples_seen\u001b[38;5;241m.\u001b[39mupdate(paths)\n\u001b[1;32m    125\u001b[0m     unique_counts_per_epoch\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mlen\u001b[39m(unique_samples_seen))  \u001b[38;5;66;03m# Store the count\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/vi_trans/lib/python3.10/site-packages/torch/utils/data/dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/miniconda3/envs/vi_trans/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1329\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data)\n\u001b[1;32m   1328\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m-> 1329\u001b[0m idx, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1330\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1331\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable:\n\u001b[1;32m   1332\u001b[0m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/vi_trans/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1295\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1291\u001b[0m     \u001b[38;5;66;03m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[1;32m   1292\u001b[0m     \u001b[38;5;66;03m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[1;32m   1293\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1294\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m-> 1295\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1296\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[1;32m   1297\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/miniconda3/envs/vi_trans/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1133\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1120\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_try_get_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m_utils\u001b[38;5;241m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[1;32m   1121\u001b[0m     \u001b[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[1;32m   1122\u001b[0m     \u001b[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1130\u001b[0m     \u001b[38;5;66;03m# Returns a 2-tuple:\u001b[39;00m\n\u001b[1;32m   1131\u001b[0m     \u001b[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1133\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1134\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n\u001b[1;32m   1135\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1136\u001b[0m         \u001b[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[1;32m   1137\u001b[0m         \u001b[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[1;32m   1138\u001b[0m         \u001b[38;5;66;03m# worker failures.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/vi_trans/lib/python3.10/multiprocessing/queues.py:113\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m block:\n\u001b[1;32m    112\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m deadline \u001b[38;5;241m-\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic()\n\u001b[0;32m--> 113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    114\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_poll():\n",
      "File \u001b[0;32m~/miniconda3/envs/vi_trans/lib/python3.10/multiprocessing/connection.py:257\u001b[0m, in \u001b[0;36m_ConnectionBase.poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_closed()\n\u001b[1;32m    256\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_readable()\n\u001b[0;32m--> 257\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/vi_trans/lib/python3.10/multiprocessing/connection.py:424\u001b[0m, in \u001b[0;36mConnection._poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    423\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_poll\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout):\n\u001b[0;32m--> 424\u001b[0m     r \u001b[38;5;241m=\u001b[39m \u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    425\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(r)\n",
      "File \u001b[0;32m~/miniconda3/envs/vi_trans/lib/python3.10/multiprocessing/connection.py:931\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    928\u001b[0m     deadline \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic() \u001b[38;5;241m+\u001b[39m timeout\n\u001b[1;32m    930\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 931\u001b[0m     ready \u001b[38;5;241m=\u001b[39m \u001b[43mselector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    932\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ready:\n\u001b[1;32m    933\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [key\u001b[38;5;241m.\u001b[39mfileobj \u001b[38;5;28;01mfor\u001b[39;00m (key, events) \u001b[38;5;129;01min\u001b[39;00m ready]\n",
      "File \u001b[0;32m~/miniconda3/envs/vi_trans/lib/python3.10/selectors.py:416\u001b[0m, in \u001b[0;36m_PollLikeSelector.select\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    414\u001b[0m ready \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    415\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 416\u001b[0m     fd_event_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_selector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpoll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n\u001b[1;32m    418\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ready\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Created an instance of DataLoaderEpochsCalculation and performed the comparison\n",
    "epoch_dataloader_b = DataLoaderEpochsCalculation(feature_file_path, label_file_path, img_path_file_path, num_categories, batch_size)\n",
    "epochs_needed_b = epoch_dataloader_b.loop_dataloader_and_save(save_path)\n",
    "print(\"Epochs needed to see all samples:\", epochs_needed_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating Total Epochs needed to see all :259865 image samples.\n",
    "After epoch 0, unique samples seen: 158865\n",
    "After epoch 1, unique samples seen: 216403\n",
    "After epoch 2, unique samples seen: 239527\n",
    "After epoch 3, unique samples seen: 249328\n",
    "After epoch 4, unique samples seen: 253882\n",
    "After epoch 5, unique samples seen: 256088\n",
    "After epoch 6, unique samples seen: 257227\n",
    "After epoch 7, unique samples seen: 257906\n",
    "After epoch 8, unique samples seen: 258319\n",
    "After epoch 9, unique samples seen: 258584\n",
    "After epoch 10, unique samples seen: 258764\n",
    "After epoch 11, unique samples seen: 258915\n",
    "After epoch 12, unique samples seen: 259022\n",
    "After epoch 13, unique samples seen: 259091\n",
    "After epoch 14, unique samples seen: 259171\n",
    "After epoch 15, unique samples seen: 259248\n",
    "After epoch 16, unique samples seen: 259293\n",
    "After epoch 17, unique samples seen: 259347\n",
    "After epoch 18, unique samples seen: 259385\n",
    "After epoch 19, unique samples seen: 259415\n",
    "After epoch 20, unique samples seen: 259445\n",
    "After epoch 21, unique samples seen: 259470\n",
    "After epoch 22, unique samples seen: 259492\n",
    "After epoch 23, unique samples seen: 259517\n",
    "After epoch 24, unique samples seen: 259535\n",
    "After epoch 25, unique samples seen: 259562\n",
    "After epoch 26, unique samples seen: 259587\n",
    "After epoch 27, unique samples seen: 259603\n",
    "After epoch 28, unique samples seen: 259628\n",
    "After epoch 29, unique samples seen: 259638\n",
    "After epoch 30, unique samples seen: 259648\n",
    "After epoch 31, unique samples seen: 259663\n",
    "After epoch 32, unique samples seen: 259673\n",
    "After epoch 33, unique samples seen: 259683\n",
    "After epoch 34, unique samples seen: 259691\n",
    "After epoch 35, unique samples seen: 259704\n",
    "After epoch 36, unique samples seen: 259715\n",
    "After epoch 37, unique samples seen: 259726\n",
    "After epoch 38, unique samples seen: 259739\n",
    "After epoch 39, unique samples seen: 259746\n",
    "After epoch 40, unique samples seen: 259752\n",
    "After epoch 41, unique samples seen: 259765\n",
    "After epoch 42, unique samples seen: 259769\n",
    "After epoch 43, unique samples seen: 259780\n",
    "After epoch 44, unique samples seen: 259783\n",
    "After epoch 45, unique samples seen: 259791\n",
    "After epoch 46, unique samples seen: 259797\n",
    "After epoch 47, unique samples seen: 259802\n",
    "After epoch 48, unique samples seen: 259805\n",
    "After epoch 49, unique samples seen: 259808\n",
    "After epoch 50, unique samples seen: 259809\n",
    "After epoch 51, unique samples seen: 259812\n",
    "After epoch 52, unique samples seen: 259812\n",
    "After epoch 53, unique samples seen: 259817\n",
    "After epoch 54, unique samples seen: 259824\n",
    "After epoch 55, unique samples seen: 259828\n",
    "After epoch 56, unique samples seen: 259831\n",
    "After epoch 57, unique samples seen: 259834\n",
    "After epoch 58, unique samples seen: 259837\n",
    "After epoch 59, unique samples seen: 259837\n",
    "After epoch 60, unique samples seen: 259838\n",
    "After epoch 61, unique samples seen: 259840\n",
    "After epoch 62, unique samples seen: 259843\n",
    "After epoch 63, unique samples seen: 259844\n",
    "After epoch 64, unique samples seen: 259845\n",
    "After epoch 65, unique samples seen: 259846\n",
    "After epoch 66, unique samples seen: 259850\n",
    "After epoch 67, unique samples seen: 259851\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dinov2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
