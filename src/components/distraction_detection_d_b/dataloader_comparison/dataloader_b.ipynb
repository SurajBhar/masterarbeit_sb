{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from scipy.stats import cumfreq\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from scipy.stats import entropy\n",
    "from collections import Counter\n",
    "\n",
    "from b_weightedimagedataset import WeightedImageDataset\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import hdbscan\n",
    "\n",
    "\n",
    "CATEGORY_MAPPING = {\n",
    "    '_non_distracted': 0, 'distracted': 1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define file paths and parameters\n",
    "feature_file_path = '/home/sur06423/hiwi/vit_exp/vision_tranformer_baseline/src/components/distraction_detection_d_b/clustering_experiments/features_split_0_kinect_rgb/all_split_0_rgb_features.pkl'\n",
    "label_file_path = '/home/sur06423/hiwi/vit_exp/vision_tranformer_baseline/src/components/distraction_detection_d_b/clustering_experiments/features_split_0_kinect_rgb/all_split_0_rgb_labels.pkl'\n",
    "img_path_file_path = '/home/sur06423/hiwi/vit_exp/vision_tranformer_baseline/src/components/distraction_detection_d_b/clustering_experiments/features_split_0_kinect_rgb/all_split_0_rgb_imagepaths.pkl'\n",
    "num_categories = 2\n",
    "batch_size = 1024\n",
    "save_path = '/home/sur06423/hiwi/vit_exp/vision_tranformer_baseline/src/components/distraction_detection_d_b/KL_results'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(feature_file_path, label_file_path, img_path_file_path):\n",
    "    with open(feature_file_path, 'rb') as file:\n",
    "        features = pickle.load(file)\n",
    "    with open(label_file_path, 'rb') as file:\n",
    "        labels = pickle.load(file)\n",
    "    with open(img_path_file_path, 'rb') as file:\n",
    "        img_paths = pickle.load(file)\n",
    "    return features, labels, img_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "features, labels, img_paths = load_data(feature_file_path, label_file_path, img_path_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The size of RGB Kinect DAA dataset (split_0) is 259865"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "259865"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Each extracted feature corresponds to a size of 1280"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1280"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(features[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "259865"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# There are 254 batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "254"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(img_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All batches contain 1024 images except last batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1024"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(img_paths[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Last Batch Contains Only 793 Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "793"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(img_paths[253])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch conversion of precomputed features, Batches = 254, Batch Size 1024, Feature size: [1,1280]\n",
    "features_loader = [features[i:i+1024] for i in range(0, len(features), 1024)]\n",
    "gt_labels_loader = [labels[i:i+1024] for i in range(0, len(labels), 1024)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "254"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(features_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "793"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(features_loader[253])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from b_weightedimagedataset import WeightedImageDataset\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import hdbscan\n",
    "\n",
    "import os\n",
    "import getpass\n",
    "import sys\n",
    "\n",
    "class DataLoaderEpochsCalculation:\n",
    "    def __init__(self, feature_file_path, label_file_path, img_path_file_path, num_categories, batch_size):\n",
    "        self.batch_size = batch_size\n",
    "        self.num_categories = num_categories\n",
    "        self.features, self.labels, self.img_paths_list = self.load_data(feature_file_path, label_file_path, img_path_file_path)\n",
    "        self.image_paths_all = [path for sublist in self.img_paths_list for path in sublist]\n",
    "        self.dataloader_b, self.weights_list, self.all_labels, self.all_cluster_counts = self.initialize_dataloaders()\n",
    "\n",
    "    def load_data(self, feature_file_path, label_file_path, img_path_file_path):\n",
    "        with open(feature_file_path, 'rb') as file:\n",
    "            features = pickle.load(file)\n",
    "        with open(label_file_path, 'rb') as file:\n",
    "            labels = pickle.load(file)\n",
    "        with open(img_path_file_path, 'rb') as file:\n",
    "            img_paths = pickle.load(file)\n",
    "        return features, labels, img_paths\n",
    "\n",
    "    def initialize_dataloaders(self):\n",
    "        # Batch conversion of precomputed features, Batches = 254, Batch Size 1024, Feature size: [1,1280]\n",
    "        features_loader = [self.features[i:i+1024] for i in range(0, len(self.features), 1024)]\n",
    "        gt_labels_loader = [self.labels[i:i+1024] for i in range(0, len(self.labels), 1024)]\n",
    "\n",
    "        # Get the weights\n",
    "        weights_list, all_labels, all_cluster_counts = self.process_batches(features_loader)\n",
    "        dataset_b = WeightedImageDataset(self.img_paths_list, weights_list, gt_labels_loader)\n",
    "        sampler_b = WeightedRandomSampler(dataset_b.weights, num_samples=len(dataset_b.weights), replacement=True)\n",
    "        dataloader_b = DataLoader(dataset_b, batch_size=self.batch_size, sampler=sampler_b, num_workers=10)\n",
    "\n",
    "        return dataloader_b, weights_list, all_labels, all_cluster_counts\n",
    "\n",
    "    def compute_weights_cosine_dist(self, features):\n",
    "        cosine_dist_matrix = 1 - cosine_similarity(features).astype(np.float64)\n",
    "        # Using Updated HDBSCAN for clustering with tuned Hyperparameters\n",
    "        clusterer = hdbscan.HDBSCAN(min_cluster_size=25, \n",
    "                                    min_samples=1, \n",
    "                                    cluster_selection_epsilon=0.0, \n",
    "                                    metric='precomputed', \n",
    "                                    cluster_selection_method='eom', \n",
    "                                    allow_single_cluster=False)\n",
    "        # clusterer = hdbscan.HDBSCAN(min_cluster_size=2, metric='precomputed', cluster_selection_method='eom')\n",
    "        labels = clusterer.fit_predict(cosine_dist_matrix)\n",
    "\n",
    "        weights = np.zeros_like(labels, dtype=float)\n",
    "        unique_labels = np.unique(labels)\n",
    "        noise_label = -1\n",
    "        # Initialize variables for managing the new outlier clusters\n",
    "        max_label = labels.max()\n",
    "        current_outlier_cluster_label = max_label + 1\n",
    "        outlier_cluster_count = 0\n",
    "\n",
    "        for label in unique_labels:\n",
    "            if label == noise_label:\n",
    "                # Process each noise point\n",
    "                for noise_index in np.where(labels == noise_label)[0]:\n",
    "                    # Assign it to the current outlier cluster\n",
    "                    labels[noise_index] = current_outlier_cluster_label\n",
    "                    outlier_cluster_count += 1\n",
    "                    weights[noise_index] = 0.001  # Assign weight as 0.001 Exp9\n",
    "\n",
    "                    # If the outlier cluster reaches its max size, move to a new one\n",
    "                    if outlier_cluster_count >= 50:\n",
    "                        current_outlier_cluster_label += 1\n",
    "                        outlier_cluster_count = 0\n",
    "            else:\n",
    "                # For non-noise points, distribute weights evenly within clusters\n",
    "                indices = np.where(labels == label)[0]\n",
    "                weights[indices] = 1.0 / len(indices)\n",
    "\n",
    "        total_clusters = len(np.unique(labels)) - 1  # Exclude the original noise label\n",
    "\n",
    "        return weights, labels, total_clusters\n",
    "\n",
    "    def process_batches(self, dataloader):\n",
    "        all_weights = []\n",
    "        all_labels = []\n",
    "        all_cluster_counts = []\n",
    "        for batch_features in dataloader:\n",
    "            weights, labels, total_clusters = self.compute_weights_cosine_dist(batch_features)\n",
    "            all_weights.append(weights)\n",
    "            all_labels.append(labels)\n",
    "            all_cluster_counts.append(total_clusters)\n",
    "\n",
    "        return all_weights, all_labels, all_cluster_counts\n",
    "    \n",
    "    ##############################################################################\n",
    "\n",
    "    def calculate_epochs_to_see_all_samples(self, dataloader, total_unique_samples):\n",
    "        unique_samples_seen = set()\n",
    "        unique_counts_per_epoch = []  # List to store counts after each epoch\n",
    "        epochs = 0\n",
    "        while len(unique_samples_seen) < total_unique_samples:\n",
    "            for _, _, _, paths in dataloader:\n",
    "                unique_samples_seen.update(paths)\n",
    "            unique_counts_per_epoch.append(len(unique_samples_seen))  # Store the count\n",
    "            print(f'After epoch {epochs}, unique samples seen: {len(unique_samples_seen)}')\n",
    "\n",
    "            # Call setup_ccname at epoch 0 and then every 15 epochs\n",
    "            #if epochs == 0 or (epochs % 10 == 0 and epochs != 0):\n",
    "            #    setup_ccname()\n",
    "\n",
    "            epochs += 1\n",
    "\n",
    "            if epochs > 1000:  # Safety check to avoid infinite loop\n",
    "                break\n",
    "\n",
    "        # Plot the results\n",
    "        self.plot_unique_samples_per_epoch(unique_counts_per_epoch, epochs)\n",
    "\n",
    "        return epochs\n",
    "    \n",
    "    def plot_unique_samples_per_epoch(self, unique_counts_per_epoch, epochs):\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(range(1, epochs + 1), unique_counts_per_epoch, marker='o')\n",
    "        plt.title('Unique Samples Seen Over Epochs')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Cumulative Unique Samples Seen')\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "\n",
    "    ################### Save the Results ######################################\n",
    "\n",
    "    def save_results_to_pickle(self, data, file_name):\n",
    "        with open(file_name, 'wb') as file:\n",
    "            pickle.dump(data, file)\n",
    "\n",
    "    def loop_dataloader_and_save(self, save_path):\n",
    "        # Calculate the number of epochs to see all unique samples\n",
    "        total_unique_samples = len(set(self.image_paths_all))  # all image paths are unique\n",
    "        print(f\"Calculating Total Epochs needed to see all :{total_unique_samples} image samples.\")\n",
    "        epochs_needed = self.calculate_epochs_to_see_all_samples(self.dataloader_b, total_unique_samples)\n",
    "        \n",
    "        # Save the result\n",
    "        self.save_results_to_pickle(epochs_needed, f'{save_path}/epochs_needed.pkl')\n",
    "        self.save_results_to_pickle(self.weights_list, f'{save_path}/weights_list_dataloader_b.pkl')\n",
    "\n",
    "        return epochs_needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define file paths and parameters\n",
    "feature_file_path = '/home/sur06423/hiwi/vit_exp/vision_tranformer_baseline/src/components/distraction_detection_d_b/clustering_experiments/features_split_0_kinect_rgb/all_split_0_rgb_features.pkl'\n",
    "label_file_path = '/home/sur06423/hiwi/vit_exp/vision_tranformer_baseline/src/components/distraction_detection_d_b/clustering_experiments/features_split_0_kinect_rgb/all_split_0_rgb_labels.pkl'\n",
    "img_path_file_path = '/home/sur06423/hiwi/vit_exp/vision_tranformer_baseline/src/components/distraction_detection_d_b/clustering_experiments/features_split_0_kinect_rgb/all_split_0_rgb_imagepaths.pkl'\n",
    "num_categories = 2\n",
    "batch_size = 1024\n",
    "save_path = '/home/sur06423/hiwi/vit_exp/vision_tranformer_baseline/src/components/distraction_detection_d_b'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoaderComparisonKL:\n",
    "    def __init__(self, feature_file_path, label_file_path, img_path_file_path, num_categories, batch_size):\n",
    "        self.batch_size = batch_size\n",
    "        self.num_categories = num_categories\n",
    "        self.features, self.labels, self.img_paths = self.load_data(feature_file_path, label_file_path, img_path_file_path)\n",
    "        self.dataloader_a, self.dataloader_b, self.weights_list, self.pred_labels_b, self.pred_cluster_counts, self.n_clusters_b_noise = self.initialize_dataloaders()\n",
    "\n",
    "    def load_data(self, feature_file_path, label_file_path, img_path_file_path):\n",
    "        with open(feature_file_path, 'rb') as file:\n",
    "            features = pickle.load(file)\n",
    "        with open(label_file_path, 'rb') as file:\n",
    "            labels = pickle.load(file)\n",
    "        with open(img_path_file_path, 'rb') as file:\n",
    "            img_paths = pickle.load(file)\n",
    "        return features, labels, img_paths\n",
    "\n",
    "    def initialize_dataloaders(self):\n",
    "        # CustomImageDataset and WeightedImageDataset initialization\n",
    "        transform_a = transforms.Compose([\n",
    "                transforms.Resize((224, 224)),  # Resize the image to a fixed size (224x224)\n",
    "                transforms.ToTensor(),          # Convert the image to a PyTorch tensor\n",
    "                transforms.Normalize(\n",
    "                    mean=[0.485, 0.456, 0.406],  # Normalize the image channels (mean)\n",
    "                    std=[0.229, 0.224, 0.225]    # Normalize the image channels (std)\n",
    "                )\n",
    "            ])\n",
    "        dataset_a = ImageFolder(root_dir='/net/polaris/storage/deeplearning/sur_data/binary_rgb_daa/split_0/train', transform=transform_a)\n",
    "        dataloader_a = DataLoader(dataset_a, batch_size=self.batch_size, shuffle=True, num_workers=10, drop_last=False)\n",
    "\n",
    "        # Batch conversion of precomputed features, Batches = 254, Batch Size 1024, Feature size: [1,1280]\n",
    "        features_loader = [self.features[i:i+1024] for i in range(0, len(self.features), 1024)]\n",
    "        gt_labels_loader = [self.labels[i:i+1024] for i in range(0, len(self.labels), 1024)]\n",
    "\n",
    "        # Get the weights\n",
    "        weights_list, pred_labels_b, pred_cluster_counts, n_clusters_b_noise, n_noise = self.process_batches(features_loader)\n",
    "        dataset_b = WeightedImageDataset(self.img_paths, weights_list, gt_labels_loader)\n",
    "        sampler_b = WeightedRandomSampler(dataset_b.weights, num_samples=len(dataset_b.weights), replacement=True)\n",
    "        dataloader_b = DataLoader(dataset_b, batch_size=self.batch_size, sampler=sampler_b, num_workers=10)\n",
    "\n",
    "        return dataloader_a, dataloader_b, weights_list, pred_labels_b, pred_cluster_counts, n_clusters_b_noise\n",
    "\n",
    "    def compute_weights_cosine_dist(self, features):\n",
    "        cosine_dist_matrix = 1 - cosine_similarity(features).astype(np.float64)\n",
    "        clusterer = hdbscan.HDBSCAN(min_cluster_size=2, metric='precomputed', cluster_selection_method='eom')\n",
    "        labels = clusterer.fit_predict(cosine_dist_matrix)\n",
    "\n",
    "        weights = np.zeros_like(labels, dtype=float)\n",
    "        unique_labels = np.unique(labels)\n",
    "        noise_label = -1\n",
    "        max_label = unique_labels.max()\n",
    "\n",
    "        num_clusters_before_noise = len(unique_labels[unique_labels != noise_label])\n",
    "        num_noise_points = len(labels[labels == noise_label])\n",
    "\n",
    "        for label in unique_labels:\n",
    "            indices = np.where(labels == label)[0]\n",
    "            group_size = len(indices)\n",
    "\n",
    "            if label == noise_label:\n",
    "                for noise_index in indices:\n",
    "                    max_label += 1\n",
    "                    weights[noise_index] = 1\n",
    "                    labels[noise_index] = max_label\n",
    "            else:\n",
    "                weights[indices] = 1.0 / group_size\n",
    "\n",
    "        total_clusters = len(np.unique(labels))\n",
    "        return weights, labels, total_clusters, num_clusters_before_noise, num_noise_points\n",
    "\n",
    "\n",
    "    def process_batches(self, dataloader):\n",
    "        all_weights = []\n",
    "        all_labels = []\n",
    "        all_cluster_counts = []\n",
    "        n_clusters_b_noise = []\n",
    "        n_noise = []\n",
    "\n",
    "        for batch_features in dataloader:\n",
    "            weights, labels, total_clusters, num_clusters_before_noise, num_noise_points = self.compute_weights_cosine_dist(batch_features)\n",
    "            all_weights.append(weights)\n",
    "            all_labels.append(labels)\n",
    "            all_cluster_counts.append(total_clusters)\n",
    "            n_clusters_b_noise.append(num_clusters_before_noise)\n",
    "            n_noise.append(num_noise_points)\n",
    "\n",
    "        return all_weights, all_labels, all_cluster_counts, n_clusters_b_noise, n_noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Create an instance of DataLoaderComparisonKL and perform the comparison\n",
    "comparison_kl = DataLoaderComparisonKL(feature_file_path, label_file_path, img_path_file_path, num_categories, batch_size)\n",
    "counts_a, counts_b, kl_divergences_a, kl_divergences_b, b_unique_images_per_batch, b_total_unique_samples, b_most_picked_per_batch, tuple_most_common_sample = comparison_kl.compare_dataloaders_and_save(save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from b_weightedimagedataset import WeightedImageDataset\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import hdbscan\n",
    "\n",
    "import os\n",
    "import getpass\n",
    "import sys\n",
    "\n",
    "def setup_ccname():\n",
    "    user=getpass.getuser()\n",
    "    # check if k5start is running, exit otherwise\n",
    "    try:\n",
    "        pid=open(\"/tmp/k5pid_\"+user).read().strip()\n",
    "        os.kill(int(pid), 0)\n",
    "    except:\n",
    "        sys.stderr.write(\"Unable to setup KRB5CCNAME!\\nk5start not running!\\n\")\n",
    "        sys.exit(1)\n",
    "    try:\n",
    "        ccname=open(\"/tmp/kccache_\"+user).read().split(\"=\")[1].strip()\n",
    "        os.environ['KRB5CCNAME']=ccname\n",
    "    except:\n",
    "        sys.stderr.write(\"Unable to setup KRB5CCNAME!\\nmaybe k5start not running?\\n\")\n",
    "        sys.exit(1)\n",
    "\n",
    "class DataLoaderEpochsCalculation:\n",
    "    def __init__(self, feature_file_path, label_file_path, img_path_file_path, num_categories, batch_size):\n",
    "        self.batch_size = batch_size\n",
    "        self.num_categories = num_categories\n",
    "        self.features, self.labels, self.img_paths_list = self.load_data(feature_file_path, label_file_path, img_path_file_path)\n",
    "        self.image_paths_all = [path for sublist in self.img_paths_list for path in sublist]\n",
    "        self.dataloader_b, self.weights_list, self.all_labels, self.all_cluster_counts = self.initialize_dataloaders()\n",
    "\n",
    "    def load_data(self, feature_file_path, label_file_path, img_path_file_path):\n",
    "        with open(feature_file_path, 'rb') as file:\n",
    "            features = pickle.load(file)\n",
    "        with open(label_file_path, 'rb') as file:\n",
    "            labels = pickle.load(file)\n",
    "        with open(img_path_file_path, 'rb') as file:\n",
    "            img_paths = pickle.load(file)\n",
    "        return features, labels, img_paths\n",
    "\n",
    "    def initialize_dataloaders(self):\n",
    "        # Batch conversion of precomputed features, Batches = 254, Batch Size 1024, Feature size: [1,1280]\n",
    "        features_loader = [self.features[i:i+1024] for i in range(0, len(self.features), 1024)]\n",
    "        gt_labels_loader = [self.labels[i:i+1024] for i in range(0, len(self.labels), 1024)]\n",
    "\n",
    "        # Get the weights\n",
    "        weights_list, all_labels, all_cluster_counts = self.process_batches(features_loader)\n",
    "        dataset_b = WeightedImageDataset(self.img_paths_list, weights_list, gt_labels_loader)\n",
    "        sampler_b = WeightedRandomSampler(dataset_b.weights, num_samples=len(dataset_b.weights), replacement=True)\n",
    "        dataloader_b = DataLoader(dataset_b, batch_size=self.batch_size, sampler=sampler_b, num_workers=10)\n",
    "\n",
    "        return dataloader_b, weights_list, all_labels, all_cluster_counts\n",
    "\n",
    "    def compute_weights_cosine_dist(self, features):\n",
    "        cosine_dist_matrix = 1 - cosine_similarity(features).astype(np.float64)\n",
    "        # Using Updated HDBSCAN for clustering with tuned Hyperparameters\n",
    "        clusterer = hdbscan.HDBSCAN(min_cluster_size=25, \n",
    "                                    min_samples=1, \n",
    "                                    cluster_selection_epsilon=0.0, \n",
    "                                    metric='precomputed', \n",
    "                                    cluster_selection_method='eom', \n",
    "                                    allow_single_cluster=False)\n",
    "        # clusterer = hdbscan.HDBSCAN(min_cluster_size=2, metric='precomputed', cluster_selection_method='eom')\n",
    "        labels = clusterer.fit_predict(cosine_dist_matrix)\n",
    "\n",
    "        weights = np.zeros_like(labels, dtype=float)\n",
    "        unique_labels = np.unique(labels)\n",
    "        noise_label = -1\n",
    "        # Initialize variables for managing the new outlier clusters\n",
    "        max_label = labels.max()\n",
    "        current_outlier_cluster_label = max_label + 1\n",
    "        outlier_cluster_count = 0\n",
    "\n",
    "        for label in unique_labels:\n",
    "            if label == noise_label:\n",
    "                # Process each noise point\n",
    "                for noise_index in np.where(labels == noise_label)[0]:\n",
    "                    # Assign it to the current outlier cluster\n",
    "                    labels[noise_index] = current_outlier_cluster_label\n",
    "                    outlier_cluster_count += 1\n",
    "                    weights[noise_index] = 0.01  # Assign weight as 0.01\n",
    "\n",
    "                    # If the outlier cluster reaches its max size, move to a new one\n",
    "                    if outlier_cluster_count >= 50:\n",
    "                        current_outlier_cluster_label += 1\n",
    "                        outlier_cluster_count = 0\n",
    "            else:\n",
    "                # For non-noise points, distribute weights evenly within clusters\n",
    "                indices = np.where(labels == label)[0]\n",
    "                weights[indices] = 1.0 / len(indices)\n",
    "\n",
    "        total_clusters = len(np.unique(labels)) - 1  # Exclude the original noise label\n",
    "\n",
    "        return weights, labels, total_clusters\n",
    "\n",
    "    def process_batches(self, dataloader):\n",
    "        all_weights = []\n",
    "        all_labels = []\n",
    "        all_cluster_counts = []\n",
    "        for batch_features in dataloader:\n",
    "            weights, labels, total_clusters = self.compute_weights_cosine_dist(batch_features)\n",
    "            all_weights.append(weights)\n",
    "            all_labels.append(labels)\n",
    "            all_cluster_counts.append(total_clusters)\n",
    "\n",
    "        return all_weights, all_labels, all_cluster_counts\n",
    "    \n",
    "    ##############################################################################\n",
    "\n",
    "    def calculate_epochs_to_see_all_samples(self, dataloader, total_unique_samples):\n",
    "        unique_samples_seen = set()\n",
    "        unique_counts_per_epoch = []  # List to store counts after each epoch\n",
    "        epochs = 0\n",
    "        while len(unique_samples_seen) < total_unique_samples:\n",
    "            setup_ccname()\n",
    "            for _, _, _, paths in dataloader:\n",
    "                unique_samples_seen.update(paths)\n",
    "            unique_counts_per_epoch.append(len(unique_samples_seen))  # Store the count\n",
    "            print(f'After epoch {epochs}, unique samples seen: {len(unique_samples_seen)}')\n",
    "\n",
    "            # Call setup_ccname at epoch 0 and then every 15 epochs\n",
    "            #if epochs == 0 or (epochs % 10 == 0 and epochs != 0):\n",
    "            #    setup_ccname()\n",
    "\n",
    "            epochs += 1\n",
    "\n",
    "            if epochs > 1000:  # Safety check to avoid infinite loop\n",
    "                break\n",
    "\n",
    "        # Plot the results\n",
    "        self.plot_unique_samples_per_epoch(unique_counts_per_epoch, epochs)\n",
    "\n",
    "        return epochs\n",
    "    \n",
    "    def plot_unique_samples_per_epoch(self, unique_counts_per_epoch, epochs):\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(range(1, epochs + 1), unique_counts_per_epoch, marker='o')\n",
    "        plt.title('Unique Samples Seen Over Epochs')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Cumulative Unique Samples Seen')\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "\n",
    "    ################### Save the Results ######################################\n",
    "\n",
    "    def save_results_to_pickle(self, data, file_name):\n",
    "        with open(file_name, 'wb') as file:\n",
    "            pickle.dump(data, file)\n",
    "\n",
    "    def loop_dataloader_and_save(self, save_path):\n",
    "        # Calculate the number of epochs to see all unique samples\n",
    "        total_unique_samples = len(set(self.image_paths_all))  # all image paths are unique\n",
    "        print(f\"Calculating Total Epochs needed to see all :{total_unique_samples} image samples.\")\n",
    "        epochs_needed = self.calculate_epochs_to_see_all_samples(self.dataloader_b, total_unique_samples)\n",
    "        \n",
    "        # Save the result\n",
    "        self.save_results_to_pickle(epochs_needed, f'{save_path}/epochs_needed.pkl')\n",
    "        self.save_results_to_pickle(self.weights_list, f'{save_path}/weights_list_dataloader_b.pkl')\n",
    "\n",
    "        return epochs_needed"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dinov2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
