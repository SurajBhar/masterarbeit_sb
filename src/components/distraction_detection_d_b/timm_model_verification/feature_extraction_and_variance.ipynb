{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print('GPU device:',torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print('No GPU avaialable, Using CPU')\n",
    "\n",
    "torch.cuda.set_device(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "from typing import Tuple, Dict, List\n",
    "from torchvision import transforms\n",
    "\n",
    "class BinaryClassificationDataset(Dataset):\n",
    "    def __init__(self, targ_dir: str, transform=None, feature_extractor=None, device=None) -> None:\n",
    "        self.paths = list(pathlib.Path(targ_dir).glob(\"*/*/*.png\"))\n",
    "        self.transform = transform\n",
    "        self.feature_extractor = feature_extractor\n",
    "        self.device = device\n",
    "        self.classes, self.class_to_idx = self.find_classes(targ_dir)\n",
    "        \n",
    "        self.non_distracted_classes = {'sitting_still', 'entering_car', 'exiting_car'}\n",
    "        self.class_to_idx_binary = {cls_name: 0 if cls_name in self.non_distracted_classes else 1 for cls_name in self.classes}\n",
    "        \n",
    "        # Map binary labels to class names\n",
    "        self.binary_label_to_class_name = {0: 'non_distracted', 1: 'distracted'}\n",
    "\n",
    "    def load_image(self, index: int) -> Image.Image:\n",
    "        image_path = self.paths[index]\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        return image\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.paths)\n",
    "\n",
    "    def find_classes(self, directory: str) -> Tuple[List[str], Dict[str, int]]:\n",
    "        classes = sorted(entry.name for entry in os.scandir(directory) if entry.is_dir())\n",
    "        if not classes:\n",
    "            raise FileNotFoundError(f\"Couldn't find any classes in {directory}.\")\n",
    "        class_to_idx = {cls_name: i for i, cls_name in enumerate(classes)}\n",
    "        return classes, class_to_idx\n",
    "\n",
    "    def __getitem__(self, index: int) -> Tuple[Dict, np.ndarray]:\n",
    "        image_path = self.paths[index]\n",
    "        image = self.load_image(index)\n",
    "        class_name = image_path.parent.parent.name\n",
    "        class_idx = self.class_to_idx[class_name]\n",
    "        class_idx_binary = self.class_to_idx_binary[class_name]\n",
    "        class_name_binary = self.binary_label_to_class_name[class_idx_binary]\n",
    "        \n",
    "        # Prepare sample information\n",
    "        sample = {\n",
    "            'image_path': str(image_path),\n",
    "            'class_idx_binary': class_idx_binary,\n",
    "            'class_idx_original': class_idx,\n",
    "            'class_name_binary': class_name_binary,\n",
    "            'class_name_original': class_name,\n",
    "        }\n",
    "        \n",
    "        # Extract features if a feature extractor and device are provided\n",
    "        features = np.array([])  # Default to an empty array if no feature extraction is performed\n",
    "        if self.feature_extractor and self.device and self.transform:\n",
    "            image_tensor = self.transform(image).unsqueeze(0).to(self.device)\n",
    "            with torch.no_grad():\n",
    "                features = self.feature_extractor(image_tensor)\n",
    "                features = features.squeeze(0).cpu().numpy()\n",
    "        \n",
    "        return sample, features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import timm\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from multiprocessing import Pool\n",
    "import pickle\n",
    "\n",
    "def load_and_preprocess_image(image_path, transform):\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    return transform(image)\n",
    "\n",
    "def extract_features(sample_info, model, data_transforms, device):\n",
    "    image_path = sample_info['image_path']\n",
    "    image = load_and_preprocess_image(image_path, data_transforms)\n",
    "    img_tensor = image.unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        feature = model(img_tensor).cpu().numpy()\n",
    "    return feature.squeeze(), sample_info\n",
    "\n",
    "def worker_init_fn(worker_id):\n",
    "    torch_seed = torch.initial_seed()\n",
    "    np.random.seed(torch_seed % 2**32)\n",
    "\n",
    "def process_chunk(chunk, model_name, data_transforms, gpu_id):\n",
    "    device = f'cuda:{gpu_id}'\n",
    "    model = timm.create_model(model_name, pretrained=True, num_classes=0).eval().to(device)\n",
    "    \n",
    "    processed_samples = [extract_features(sample, model, data_transforms, device) for sample in chunk]\n",
    "    return processed_samples\n",
    "\n",
    "def parallel_feature_extraction(dataset, model_name, num_gpus=4):\n",
    "    data_config = timm.data.resolve_model_data_config(model_name)\n",
    "    data_transforms = timm.data.create_transform(**data_config, is_training=False)\n",
    "    \n",
    "    # Create a DataLoader to handle batching and multiprocessing\n",
    "    data_loader = DataLoader(dataset, batch_size=len(dataset) // num_gpus, shuffle=False, num_workers=num_gpus, worker_init_fn=worker_init_fn)\n",
    "    \n",
    "    # Using Pool to manage GPU allocation\n",
    "    with Pool(num_gpus) as p:\n",
    "        results = p.starmap(process_chunk, [(chunk, model_name, data_transforms, gpu_id % num_gpus) for gpu_id, chunk in enumerate(data_loader)])\n",
    "    \n",
    "    # Flattening the list of results\n",
    "    all_features, all_samples_info = zip(*[item for sublist in results for item in sublist])\n",
    "    \n",
    "    return all_samples_info, all_features\n",
    "\n",
    "# Function to save data to a pickle file\n",
    "def save_to_pickle(data, filename):\n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump(data, f)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    dataset_root = \"/net/polaris/storage/deeplearning/sur_data/rgb_daa/split_0/train\"\n",
    "    binary_dataset = BinaryClassificationDataset(dataset_root)\n",
    "    model_name = 'vit_huge_patch14_224.orig_in21k'\n",
    "    all_samples_info, all_features = parallel_feature_extraction(binary_dataset, model_name, num_gpus=4)\n",
    "    save_to_pickle({'samples_info': all_samples_info, 'features': all_features}, 'aggregated_features.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dinov2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
