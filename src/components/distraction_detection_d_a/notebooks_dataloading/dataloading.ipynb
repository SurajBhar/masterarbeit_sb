{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import math\n",
    "import random\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "from typing import Tuple, Dict, List\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class BinaryClassificationDataset(Dataset):\n",
    "    def __init__(self, targ_dir: str, transform=None, target_transform=None) -> None:\n",
    "        self.paths = list(pathlib.Path(targ_dir).glob(\"*/*/*.png\"))\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.classes, self.class_to_idx = self.find_classes(targ_dir)\n",
    "        \n",
    "        self.non_distracted_classes = {'sitting_still', 'entering_car', 'exiting_car'}\n",
    "        self.class_to_idx_binary = {cls_name: 0 if cls_name in self.non_distracted_classes else 1 for cls_name in self.classes}\n",
    "        \n",
    "        # Map binary labels to class names\n",
    "        self.binary_label_to_class_name = {0: 'non_distracted', 1: 'distracted'}\n",
    "\n",
    "        # Attribute for all binary labels of the dataset\n",
    "        self.all_binary_labels = [self.class_to_idx_binary[path.parent.parent.name] for path in self.paths]\n",
    "\n",
    "    def load_image(self, index: int) -> Image.Image:\n",
    "        image_path = self.paths[index]\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        return image\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.paths)\n",
    "\n",
    "    def find_classes(self, directory: str) -> Tuple[List[str], Dict[str, int]]:\n",
    "        classes = sorted(entry.name for entry in os.scandir(directory) if entry.is_dir())\n",
    "        if not classes:\n",
    "            raise FileNotFoundError(f\"Couldn't find any classes in {directory}.\")\n",
    "        class_to_idx = {cls_name: i for i, cls_name in enumerate(classes)}\n",
    "        return classes, class_to_idx\n",
    "\n",
    "    def __getitem__(self, index: int) -> Tuple[torch.Tensor, int, str]:\n",
    "        image = self.load_image(index)\n",
    "        class_name = self.paths[index].parent.parent.name\n",
    "        class_idx = self.class_to_idx[class_name]\n",
    "        class_idx_binary = self.class_to_idx_binary[class_name]\n",
    "        \n",
    "        # Convert binary label to its corresponding class name\n",
    "        class_name_binary = self.binary_label_to_class_name[class_idx_binary]\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform:\n",
    "            class_idx_binary = self.target_transform(class_idx_binary)\n",
    "        \n",
    "        # Return the image, binary class index, and binary class name\n",
    "        return image, class_idx_binary, class_idx, class_name_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = \"/net/polaris/storage/deeplearning/sur_data/rgb_daa/split_0/train\"\n",
    "val_dir = \"/net/polaris/storage/deeplearning/sur_data/rgb_daa/split_0/val\"\n",
    "test_dir = \"/net/polaris/storage/deeplearning/sur_data/rgb_daa/split_0/test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataloader(dataset: Dataset, batch_size: int, num_workers: int, prefetch_factor: int):\n",
    "    return DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        pin_memory=True,\n",
    "        shuffle=False,\n",
    "        num_workers=num_workers,\n",
    "        prefetch_factor=prefetch_factor,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size_per_gpu = 1024\n",
    "num_workers = 4\n",
    "prefetch_factor = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "pretrained_vit_weights = torchvision.models.ViT_B_16_Weights.DEFAULT\n",
    "pretrained_vit = torchvision.models.vit_b_16(weights=pretrained_vit_weights)\n",
    "\n",
    "# Freeze the base parameters\n",
    "for parameter in pretrained_vit.parameters():\n",
    "    parameter.requires_grad = False\n",
    "\n",
    "# Change the classifier head to match with binary classification:\n",
    "# {distracted_driver, non_distracted_driver}\n",
    "pretrained_vit.heads = nn.Linear(in_features=768, out_features=2)\n",
    "pretrained_vit_transforms = pretrained_vit_weights.transforms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use ImageFolder to create dataset(s)\n",
    "train_dataset = BinaryClassificationDataset(train_dir, transform=pretrained_vit_transforms)\n",
    "val_dataset = BinaryClassificationDataset(val_dir, transform=pretrained_vit_transforms)\n",
    "test_dataset = BinaryClassificationDataset(test_dir, transform=pretrained_vit_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass the adjusted batch size here\n",
    "train_dataloader = prepare_dataloader(train_dataset, batch_size_per_gpu, num_workers= num_workers, prefetch_factor=prefetch_factor)\n",
    "val_dataloader = prepare_dataloader(val_dataset, batch_size_per_gpu, num_workers= num_workers, prefetch_factor=prefetch_factor)\n",
    "test_dataloader = prepare_dataloader(test_dataset, batch_size_per_gpu, num_workers= num_workers, prefetch_factor=prefetch_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vi_trans",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
